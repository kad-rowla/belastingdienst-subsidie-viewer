import { isEmpty, mapValues, zip, isEqual as deepEqual, cloneDeep } from "lodash-es";
import { injectInPlace } from "@triply/utils/sparqlVarUtils.js";
import {
  SimpleTriplePattern,
  Operation,
  Join,
  LeftJoin,
  Filter,
  Union,
  Extend,
  Minus,
  Aggregate,
  OrderBy,
  Distinct,
  Slice,
  Service,
  ZeroOrMorePath,
  InlineData,
  EnsureBound,
  IDENTITY,
  serviceRunTimeInfo,
  TriplePattern,
} from "./Algebra/Operation.js";
import log from "./Debugging.js";
import * as sparqljs from "sparqljs";
import {
  CoalesceError,
  EvaluationResult,
  FALSE,
  TRUE,
  InvalidArgumentTypes,
  AggregationType,
  AggregationFunctionNames,
  PartialGroupConcat,
  invalidArgumentTypesError,
} from "./EvaluationResult.js";
import { AggregateFunction, FunctionName, Expression, VariableExpression } from "./Algebra/Expression.js";
import { default as ResultContext, ResultContexts } from "./ResultContext.js";
import {
  DATA_TYPES,
  GraphName,
  Variable,
  Term,
  dataFactory,
  Bindings,
  NumericDataType,
  MAX_RESULTS_IN_MEMORY,
  GEO_FUNCTIONS as GEO_FUNCTIONS,
  RdfDataset,
} from "./constants.js";
import { XPATH_FUNCTIONS } from "@triplydb/recognized-datatypes/utils/constants.js";
import {
  concat,
  contains,
  encode_for_uri,
  validateAndGetNumericDataType,
  iri,
  langmatches,
  lcase,
  lessThan,
  newLiteral,
  regex,
  replace,
  str,
  strafter,
  strbefore,
  strdt,
  strends,
  strlen,
  strstarts,
  substr,
  ucase,
  xsdboolean,
  xsddatetime,
  xsddecimal,
  xsddouble,
  xsdfloat,
  xsdinteger,
  xsdstring,
  strlang,
  lang,
  abs,
  ceil,
  floor,
  round,
  datatype,
  hashStrings,
  year,
  month,
  day,
  seconds,
  hours,
  minutes,
  timezone,
  tz,
  effectiveBooleanValue,
  effectiveBooleanValueOfTerm,
  compare,
  bnode,
  xsdint,
  xsddate,
  xsdgYear,
  xsdlong,
} from "./EvaluationFunctions.js";
import { QueryContext, QueryContextOptions } from "./QueryContext.js";
import { canonicalToNumber, decimalToRoundedString, next, validators } from "./Helpers.js";
import { v4 as randomUUID } from "uuid";
import { createHash } from "crypto";
import { FatalError, SparqlError, SpeedyError, UnsupportedError } from "./Errors.js";
import { Literal, NamedNode } from "@triplydb/data-factory/Terms.js";
import { VariableConfig } from "@triply/utils/Models.js";
import { sendSparqlSelectRequest } from "./SelectQueryRequests.js";
import { UNBOUND_VARIABLE_NAME } from "./Algebra/ASTtoAlgebra/variableScope.js";
import {
  DEFAULT_CRS,
  WktLiteralDatatype,
  lexicalToValue as wktLexicalToValue,
} from "@triplydb/recognized-datatypes/wkt.js";
import { geoProject } from "@triplydb/utils/GeoProject.js";
import { DEFAULT_UNIT, geoArea, isSupportedAreaUnit } from "@triplydb/utils/GeoArea.js";
import { isRecognized, valueToCanonical } from "@triplydb/recognized-datatypes";
import { isSupportedCrs } from "@triplydb/utils/Crs.js";

type AggregateFunctionMap = AggregationType<AggregationFunctionNames>;
type NonStandardFunctionCall = "<" | "!" | "||" | "&&" | "=" | "sameTerm" | "IF" | "COALESCE";
type StandardFunctionCall = Exclude<FunctionName, NonStandardFunctionCall>;

interface AggregateValue {
  partialUpdate: (result: EvaluationResult) => void;
  finalize: () => EvaluationResult;
  distinctIds: Set<string>;
}

export function initialResultContext() {
  return [
    new ResultContext<any>({
      bindings: {},
    }),
  ] as const;
}

export type QueryOptions = Partial<Omit<QueryContextOptions, "algebra">>;

export type AsyncBindingsIterable = AsyncIterable<Bindings<Term>>;

export type PredicateStatsAndGraphs = {
  readonly distinctSubjects: (predicate?: NamedNode<string>) => Promise<number>;
  readonly distinctObjects: (predicate?: NamedNode<string>) => Promise<number>;
  readonly subjectBranchingFactor: (predicate: NamedNode<string>) => Promise<number>;
  readonly objectBranchingFactor: (predicate: NamedNode<string>) => Promise<number>;
  readonly distinctLiteralsWithLanguageTag: (
    predicate: NamedNode<string>,
    languageTag: Literal<string>["language"],
  ) => Promise<number>;
  readonly distinctLiteralsWithDatatype: (predicate: NamedNode<string>, datatype: NamedNode<string>) => Promise<number>;
  readonly countTriples: (triple?: SimpleTriplePattern) => Promise<number>;
  readonly numTriplesMatchingPredicate: (predicate: NamedNode<string>) => Promise<number>;
  /**
   *  The graphs where a predicate exists, if it doesn't exist in all graphs present.
   *  If the predicate is in all graphs, then this function returns undefined.
   *  Otherwise it returns an array of NamedNodes.
   */
  readonly getGraphsMatchingPredicateIfNotInAllGraphs: (
    predicate: NamedNode<string>,
  ) => Promise<GraphName[] | undefined>;
};

export class Executor<BindingValue> {
  readonly getPredicateStatsAndGraphs: () => PredicateStatsAndGraphs | undefined;
  readonly executeTriplePattern: (
    operation: TriplePattern,
    resultContexts: ResultContexts<BindingValue>,
    queryContext: QueryContext,
  ) => ResultContexts<BindingValue>;
  readonly executeOrderBy: (
    operation: OrderBy,
    inputContexts: ResultContexts<BindingValue>,
    queryContext: QueryContext,
    executor: Executor<BindingValue>,
  ) => ResultContexts<BindingValue>;

  readonly getBinding: (term: Term) => BindingValue;
  /**
   * Get the term for a binding value.
   */
  readonly getTerm: (binding: BindingValue) => Term | Promise<Term>;
  readonly disableTermValidation?: boolean;

  /**
   * The rdf dataset to use by default, if the query or http-headers don't
   * specify a different rdf dataset.
   *
   * The `namedGraphs` of this RdfDataset are the source of truth for the
   * available named graphs to the engine.
   *
   * We want this property to be a function, because with supporting SPARQL UPDATE, we also want
   * to cater for dynamic stores (only in memory)
   */
  readonly defaultRdfDataset: () => RdfDataset;

  constructor(
    opts: Pick<
      Executor<BindingValue>,
      | "executeTriplePattern"
      | "executeOrderBy"
      | "getTerm"
      | "getBinding"
      | "getPredicateStatsAndGraphs"
      | "disableTermValidation"
      | "defaultRdfDataset"
    >,
  ) {
    this.executeTriplePattern = opts.executeTriplePattern;
    this.executeOrderBy = opts.executeOrderBy;
    this.getTerm = opts.getTerm;
    this.getBinding = opts.getBinding;
    this.getPredicateStatsAndGraphs = opts.getPredicateStatsAndGraphs;
    this.disableTermValidation = opts.disableTermValidation;
    this.defaultRdfDataset = opts.defaultRdfDataset;
  }

  /**
   *  Execute a query represented by an Operation. Note that the cool thing
   *  about this function is that it doesn't refer to the `BindingValue` type
   *  parameter in its arguments or return value
   */
  public query(operation: Operation, options?: QueryOptions) {
    const queryContext = new QueryContext({
      // NB! This order is important here. We want to apply the query options after the class defaults.
      ...options,
      disableTermValidation: this.disableTermValidation ?? options?.disableTermValidation,
      algebra: operation,
      rdfDataset: options?.rdfDataset ?? this.getRdfDataset(),
    });
    return {
      queryContext,
      results: this.resultContextsToRdfjsBindings(
        this.executeOperation(operation, initialResultContext(), queryContext),
        queryContext,
      ),
    };
  }

  async *resultContextsToRdfjsBindings(
    contexts: ResultContexts<BindingValue>,
    queryContext: QueryContext,
  ): AsyncGenerator<Bindings<Term>> {
    for await (const context of contexts) {
      const terms: Bindings<Term> = {};
      for (let [variable, binding] of Object.entries(context.bindings)) {
        if (binding === undefined) continue;
        terms[variable] = await this.getTerm(binding);
      }
      yield terms;
    }
  }

  /**
   * > A query service may refuse a query request if the dataset description is
   * > not acceptable to the service.
   * from: https://www.w3.org/TR/sparql11-query/#specifyingDataset
   *
   * > If there is no FROM clause, but there is one or more FROM NAMED clauses,
   * > then the dataset includes an empty graph for the default graph.
   * from: https://www.w3.org/TR/sparql11-query/#specifyingDataset
   */
  getRdfDataset(from?: sparqljs.BaseQuery["from"]): RdfDataset {
    if (from === undefined || from.default.length + from.named.length === 0) return this.defaultRdfDataset();

    const namedGraphs = new Set(this.defaultRdfDataset().namedGraphs.map(({ value }) => value));
    for (const graph of from.default) {
      if (!namedGraphs.has(graph.value)) {
        throw new SparqlError(
          `A FROM clause references a graph that is not available for querying: ${graph.value}.` +
            ` Try using 'SELECT * WHERE { GRAPH ?g {} }' to find out what graphs are available.`,
        );
      }
    }
    for (const graph of from.named) {
      if (!namedGraphs.has(graph.value)) {
        throw new SparqlError(
          `A FROM NAMED clause references a graph that is not available for querying: ${graph.value}.` +
            ` Try using 'SELECT * WHERE { GRAPH ?g {} }' to find out what graphs are available.`,
        );
      }
    }
    return {
      defaultGraph: from.default,
      namedGraphs: from.named,
    };
  }

  executeOperation(
    operation: Operation,
    resultContexts: ResultContexts<BindingValue>,
    queryContext: QueryContext,
  ): ResultContexts<BindingValue> {
    return queryContext.countResults(operation, resultContexts, (resultContexts) => {
      switch (operation.operationType) {
        case "TriplePattern":
          return this.executeTriplePattern(operation, resultContexts, queryContext);
        case "ZeroOrMorePath":
          return this.executeZeroOrMorePath(operation, resultContexts, queryContext);
        case "Join":
          return this.executeJoin(operation, resultContexts, queryContext);
        case "LeftJoin":
          return this.executeLeftJoin(operation, resultContexts, queryContext);
        case "Filter":
          return this.executeFilter(operation, resultContexts, queryContext);
        case "Union":
          return this.executeUnion(operation, resultContexts, queryContext);
        case "Extend":
          return this.executeExtend(operation, resultContexts, queryContext);
        case "Minus":
          return this.executeMinus(operation, resultContexts, queryContext);
        case "Aggregate":
          return this.executeAggregate(operation, resultContexts, queryContext);
        case "OrderBy":
          return this.executeOrderBy(operation, resultContexts, queryContext, this);
        case "Distinct":
          return this.executeDistinct(operation, resultContexts, queryContext);
        case "Slice":
          return this.executeSlice(operation, resultContexts, queryContext);
        case "Service":
          return this.executeService(operation, resultContexts, queryContext);
        case "InlineData":
          return this.executeInlineData(operation, resultContexts, queryContext);
        case "EnsureBound":
          return this.executeEnsureBound(operation, resultContexts, queryContext);
      }
    });
  }

  async *executeEnsureBound(
    operation: EnsureBound,
    resultContexts: ResultContexts<BindingValue>,
    queryContext: QueryContext,
  ) {
    for await (const context of resultContexts) {
      if (context.bindings[operation.variable]) {
        yield context;
      } else {
        const pattern = [randomUUID(), randomUUID(), randomUUID()] as const;
        yield* this.executeOperation(
          {
            operationType: "Distinct",
            variables: [operation.variable],
            inputOperation: {
              operationType: "Join",
              inputOperations: [
                { operationType: "TriplePattern", pattern, graphs: operation.graphs },
                {
                  operationType: "Union",
                  inputOperations: [pattern[0], pattern[2]].map((variable) => ({
                    operationType: "Extend",
                    variable: operation.variable,
                    variablesInScope: [variable],
                    expression: { expressionType: "Variable", variable },
                    inputOperation: IDENTITY,
                  })),
                },
              ],
            },
          },
          [context],
          queryContext,
        );
      }
    }
  }

  /**
   *  Helper function for executeZeroOrMorePath.
   *
   *  The same as https://www.w3.org/TR/sparql11-query/#defn_evalALP_1
   */
  private async *recursePaths(
    startVariable: Variable,
    startTerm: Term,
    inputOperation: Readonly<Operation>,
    end: string,
    resultContext: ResultContext<BindingValue>,
    queryContext: QueryContext,
    visitedTerms: Set<string>,
  ): AsyncGenerator<BindingValue> {
    // don't loop
    if (visitedTerms.has(startTerm.id)) {
      return;
    }
    // base case: zero-or-more means at least the start is a correct answer
    visitedTerms.add(startTerm.id);
    yield this.getBinding(startTerm);
    // recursive case:
    // from the start, make one step, then use all the ends that we found as
    // new starting places (we don't have to yield the ends, because that will
    // be done first thing in the recursive call)
    const result = this.executeOperation(inputOperation, [resultContext], queryContext);
    for await (const r of result) {
      const newStartBinding = r.bindings[end];
      if (!newStartBinding) throw new FatalError(`Missing binding for ${end}. Please contact a developer.`);
      yield* this.recursePaths(
        startVariable,
        await this.getTerm(newStartBinding),
        inputOperation,
        end,
        resultContext.addBinding(startVariable, newStartBinding),
        queryContext,
        visitedTerms,
      );
    }
  }

  /**
   *  Evaluate a zero-or-more path, recursively going over the bindings of each result in a depth-first fashion.
   *  We expect the start of such a path expression to be bound
   *  https://www.w3.org/TR/sparql11-query/#defn_evalZeroOrMorePath
   */
  private async *executeZeroOrMorePath(
    operation: Readonly<ZeroOrMorePath>,
    resultContexts: ResultContexts<BindingValue>,
    queryContext: QueryContext,
  ): AsyncGenerator<ResultContext<BindingValue>> {
    for await (const resultContext of resultContexts) {
      const visited = new Set<string>();
      // StartingBinding is the last object of the zero or more path, its a node or a variable.
      const startBinding = resultContext.bindings[operation.boundStart];

      if (!startBinding)
        throw new FatalError(
          `The starting variable, ?${operation.boundStart}, must always be bound. Please contact a developer.`,
        );
      const start = await this.getTerm(startBinding);

      // there are two cases:
      // (A) right-hand term is grounded
      // (B) right-hand term is not grounded

      const end = resultContext.bindings[operation.end]
        ? await this.getTerm(resultContext.bindings[operation.end]!)
        : undefined;
      const inputContext = end ? resultContext.removeBinding(operation.end) : resultContext;
      for await (const binding of this.recursePaths(
        operation.boundStart,
        start,
        operation.inputOperation,
        operation.end,
        inputContext,
        queryContext,
        visited,
      )) {
        //We get all results here as bindings!
        if (!end) {
          yield resultContext.addBinding(operation.end, binding);
        } else if (end.equals(await this.getTerm(binding))) {
          yield resultContext;
          // we won't ever revisit a node, and this was it! So let's just stop.
          break;
        } else {
          //end exists and doesn't equal getTerm binding then we don't want it.
        }
      }
    }
  }

  /**
   *  Execute a left-deep (inner) join.
   *
   *  For example, if we have the following join:
   *
   *    {
   *      operationType: "Join",
   *      inputOperations: [opA, opB, opC]
   *    }
   *
   *  then opA is executed first. For every result of opA, opB is executed.
   *  Finally, for every result of opB, opC is executed. The results of opC
   *  are the results of the whole join operation.
   */
  executeJoin(operation: Join, resultContexts: ResultContexts<BindingValue>, queryContext: QueryContext) {
    for (const nextOperation of operation.inputOperations) {
      resultContexts = this.executeOperation(nextOperation, resultContexts, queryContext);
    }
    return resultContexts;
  }

  async *executeLeftJoin(
    operation: LeftJoin,
    resultContexts: ResultContexts<BindingValue>,
    queryContext: QueryContext,
  ): AsyncGenerator<ResultContext<BindingValue>> {
    for await (const leftContext of this.executeOperation(operation.inputOperations[0], resultContexts, queryContext)) {
      let foundContext = false;
      for await (const joinedContext of this.executeOperation(
        operation.inputOperations[1],
        [leftContext],
        queryContext,
      )) {
        foundContext = true;
        yield joinedContext;
      }
      if (!foundContext) yield leftContext;
    }
  }

  async *executeFilter(
    operation: Filter,
    resultContexts: ResultContexts<BindingValue>,
    queryContext: QueryContext,
  ): AsyncGenerator<ResultContext<BindingValue>> {
    for await (const context of this.executeOperation(operation.inputOperation, resultContexts, queryContext)) {
      log("sparql:filter:context", "Considering context: %D", context);
      const evaluatedExpression = await this.evaluateExpression(operation.expression, context, queryContext);

      const EBV = effectiveBooleanValue(evaluatedExpression);
      if (EBV === true) {
        log("sparql:filter:true", "Yielding context!");
        yield context;
      } else if (EBV === false) {
        log("sparql:filter:false", "Withholding context!");
        continue;
      } else {
        log("sparql:filter:error", "Returned error: %D", EBV);
        continue;
      }
    }
  }

  async *executeUnion(
    operation: Union,
    resultContexts: ResultContexts<BindingValue>,
    queryContext: QueryContext,
  ): AsyncGenerator<ResultContext<BindingValue>, any, undefined> {
    for await (const context of resultContexts) {
      for (const op of operation.inputOperations) {
        yield* this.executeOperation(op, [context], queryContext);
      }
    }
  }

  async *executeExtend(
    operation: Extend,
    resultContexts: ResultContexts<BindingValue>,
    queryContext: QueryContext,
  ): AsyncGenerator<ResultContext<BindingValue>> {
    for await (let context of this.executeOperation(operation.inputOperation, resultContexts, queryContext)) {
      const result = await this.evaluateExpression(operation.expression, context, queryContext);
      log("sparql:extend", "The expression for %s evaluated to %O", operation.variable, result);
      if (result.evaluationResultType !== "error") {
        // @DECISION
        // Note that we also check whether `operation.variable` was already bound.
        // The spec says that "Extend is undefined when var in dom(Î¼)", i.e. we
        // can do whatever we like.
        // We check whether the bindings agree because we also use Extend for
        // property paths, and it's really annoying if it starts overwriting
        // stuff with incorrect values.
        if (
          operation.variable in context.bindings &&
          result.term.id !== (await this.getTerm(context.bindings[operation.variable]!)).id
        ) {
          continue; // skip incompatible combinations
        }
        context = context.addBinding(operation.variable, this.getBinding(result.term));
      }
      yield context;
    }
  }

  /**
   * The other style of negation provided in SPARQL is MINUS which evaluates both its arguments,
   * then calculates solutions in the left-hand side that are not compatible with the solutions on the right-hand side.
   * https://www.w3.org/TR/sparql11-query/#neg-minus
   *
   */

  async *executeMinus(
    operation: Minus,
    resultContexts: ResultContexts<BindingValue>,
    queryContext: QueryContext,
  ): AsyncGenerator<ResultContext<BindingValue>> {
    for await (const outerContext of this.executeOperation(
      operation.inputOperations[0],
      resultContexts,
      queryContext,
    )) {
      /**
       * There are several condition for deciding if we should yield the outerContext:
       *  - If there is no innerContext
       *  - If there is no common variable between the outerContext and any innerContext
       *  - If at least one variable in outerContext is also in innerContext, but with different
       *    binding value
       */
      let shouldSkipOuterContext = false;
      // The next line is about the first condition.
      for await (const innerContext of this.executeOperation(
        operation.inputOperations[1],
        initialResultContext(),
        queryContext,
      )) {
        for (const [variable, outerBinding] of Object.entries(outerContext.bindings)) {
          // The next line checks the second condition.
          if (Object.keys(innerContext.bindings).includes(variable)) {
            const innerBinding = innerContext.bindings[variable];
            if (!outerBinding || !innerBinding)
              throw new FatalError(
                "The variables of outer context and inner context should be always be bound in MINUS. Please contact a developer.",
              );
            const innerTerm = await this.getTerm(innerBinding);
            const outerTerm = await this.getTerm(outerBinding);
            // The next line checks the third condition
            if (innerTerm.equals(outerTerm)) {
              // If the same variable has the same term in each solution,
              // then maybe we should skip outer context.
              // But we have to do this test for every variable
              // in the outerContext bindings.
              shouldSkipOuterContext = true;
            } else {
              // If we find a mismatch between the binding values of the same variable
              // of inner and outer context, then we go to the next inner context.
              // If there is no next inner context, then proceed and yield outer context.
              shouldSkipOuterContext = false;
              break;
            }
          }
        }
        if (shouldSkipOuterContext) break;
      }
      if (!shouldSkipOuterContext) yield outerContext;
    }
  }

  /**
   * Aggregation functions are defined as a Map-<AggregationInterface> with a function that updates the value in place
   * and a finalize() to return the aggregated result
   */
  aggregateFunctionMap: AggregateFunctionMap = {
    AVG: {
      initData: () => ({ total: newLiteral("0", DATA_TYPES.XSD_INTEGER), count: 0 }),
      partialUpdate: (data, result) => {
        data.total = this.evaluateFunctionalCall([data.total, result], "+");
        data.count++;
      },
      finalizeResult: (data) => {
        if ("errorType" in data.total) return data.total;
        if (data.total.term.termType !== "Literal")
          return { errorType: "InvalidArgumentTypes", evaluationResultType: "error" } as InvalidArgumentTypes;
        return data.count > 0
          ? this.evaluateFunctionalCall([data.total, newLiteral(data.count.toString(), DATA_TYPES.XSD_INTEGER)], "/")
          : newLiteral("0", DATA_TYPES.XSD_INTEGER);
      },
    },
    COUNT: {
      initData: () => ({ count: 0 }),
      partialUpdate: (data, result) => {
        // For Count we do not increase the count if there is an error - https://www.w3.org/TR/sparql11-query/#defn_aggCount
        if ("errorType" in result) return;
        data.count++;
      },
      finalizeResult: (data) => {
        return newLiteral(data.count.toString(), DATA_TYPES.XSD_INTEGER);
      },
    },
    SUM: {
      initData: () => ({ value: newLiteral("0", DATA_TYPES.XSD_INTEGER) }),
      partialUpdate: (data, result) => {
        data.value = this.evaluateFunctionalCall([data.value, result], "+");
      },
      finalizeResult: (data) => data.value,
    },
    GROUP_CONCAT: {
      // We're leaving out `separator`, because it will always be set from the
      // algebra.
      initData: () => ({ data: newLiteral("", DATA_TYPES.XSD_STRING), count: 0 }) as PartialGroupConcat,
      partialUpdate: (data, result) => {
        data.count++;
        if (data.count == 1) {
          data.data =
            result.evaluationResultType === "value"
              ? this.evaluateFunctionalCall([data.data, result], "CONCAT")
              : result;
          return;
        }
        data.data = this.evaluateFunctionalCall(
          [data.data, newLiteral(data.separator, DATA_TYPES.XSD_STRING), result],
          "CONCAT",
        );
      },
      finalizeResult: (data) => data.data,
    },
    SAMPLE: {
      initData: () => ({ value: undefined }),
      partialUpdate: (data, result) => {
        // Don't sample error results
        if (result.evaluationResultType === "value") data.value = result.term;
      },
      finalizeResult: (data) => {
        if (data.value)
          return {
            evaluationResultType: "value",
            term: data.value,
          };
        return { errorType: "EmptyAggregateError", evaluationResultType: "error" };
      },
    },
    MIN: {
      initData: () => ({ value: undefined }),
      partialUpdate: (data, result) => {
        if (!data.value) {
          data.value = result;
          return;
        }
        let compareValue = lessThan(result, data.value);

        if ("errorType" in compareValue) {
          data.value = compareValue;
          return;
        }
        if (compareValue.term.value === "true") data.value = result;
      },
      finalizeResult: (data) => {
        if (data.value) return data.value;
        return { errorType: "EmptyAggregateError", evaluationResultType: "error" };
      },
    },
    MAX: {
      initData: () => ({ value: undefined }),
      partialUpdate: (data, result) => {
        if (!data.value) {
          data.value = result;
          return;
        }
        let compareValue = lessThan(data.value, result);

        if ("errorType" in compareValue) {
          data.value = compareValue;
          return;
        }
        if (compareValue.term.value === "true") data.value = result;
      },
      finalizeResult: (data) => {
        if (data.value) return data.value;
        return { errorType: "EmptyAggregateError", evaluationResultType: "error" };
      },
    },
  } as const;

  private initializeGroup(
    aggExpr: AggregateFunction,
    variable: Variable,
    groupToUpdate: Map<Variable, AggregateValue>,
  ) {
    const aggregationFunction = this.aggregateFunctionMap[aggExpr.function];
    // Casting to any to satisfy typescript. We know the value is compatible, as we're exchanging arguments
    // between the same aggregation function context
    const initData = aggregationFunction.initData() as any;
    // Reset the separator for GROUP CONCAT
    if (aggExpr.function === "GROUP_CONCAT") initData.separator = aggExpr.separator;

    groupToUpdate.set(variable, {
      partialUpdate: (result: EvaluationResult) => aggregationFunction.partialUpdate(initData, result),
      finalize: () => aggregationFunction.finalizeResult(initData),
      distinctIds: new Set<string>(),
    });
  }

  private async performAggregation(
    aggExpr: AggregateFunction,
    variable: Variable,
    resultContext: ResultContext<BindingValue>,
    queryContext: QueryContext,
    groupToUpdate: Map<Variable, AggregateValue>,
  ) {
    // Workaround related to https://issues.triply.cc/issues/7872
    const result =
      aggExpr.expression.expressionType === "WildCard"
        ? ({
            evaluationResultType: "value",
            term: dataFactory.literal("*", dataFactory.namedNode("https://www.triply.cc/wildcard")),
          } as const satisfies EvaluationResult)
        : await this.evaluateExpression(aggExpr.expression, resultContext, queryContext);

    if (!groupToUpdate.has(variable)) {
      this.initializeGroup(aggExpr, variable, groupToUpdate);
    }
    const variableToCheck = groupToUpdate.get(variable)!;
    /**
     * @DECISION
     * We are treating every error here as distinct, and so we only check for results with a value.
     * Each aggregate then deals with errors per aggregate.
     * https://www.w3.org/TR/sparql11-query/#defn_algAggregation
     *
     * if we find the termId we don't update the aggregate value.
     */
    if (aggExpr.distinct && result.evaluationResultType === "value") {
      if (variableToCheck.distinctIds.has(result.term.id)) return;
      variableToCheck.distinctIds.add(result.term.id);
    }
    // Update the group with the aggregation
    variableToCheck.partialUpdate(result);
  }

  async *executeAggregate(
    operation: Aggregate,
    resultsContexts: ResultContexts<BindingValue>,
    queryContext: QueryContext,
  ): AsyncGenerator<ResultContext<BindingValue>> {
    for await (const inputContext of resultsContexts) {
      const groups: Map<string, Map<Variable, AggregateValue>> = new Map();

      const getCurrentGroup = async (context: ResultContext<BindingValue>) => {
        const group: string[] = [];
        for (const expression of operation.groupingExpressions) {
          const evaluationResult = await this.evaluateExpression(expression, context, queryContext);
          group.push(evaluationResult.evaluationResultType !== "error" ? evaluationResult.term.id : "undefined");
        }
        return group.join("");
      };

      for await (const context of this.executeOperation(operation.inputOperation, [inputContext], queryContext)) {
        const currentGroup = await getCurrentGroup(context);
        for (const [variable, aggExpr] of Object.entries(operation.aggregatingExpressions)) {
          let groupToUpdate = groups.get(currentGroup);
          if (!groupToUpdate) {
            groupToUpdate = new Map();
            groups.set(currentGroup, groupToUpdate);
          }
          // Build the group with partial aggregation
          await this.performAggregation(aggExpr, variable, context, queryContext, groupToUpdate);
        }
      }

      // If the group is empty and no groupingExpression is present, use the aggregatingExpressions to set the default value
      if (isEmpty(groups) && isEmpty(operation.groupingExpressions)) {
        const groupToUpdate = new Map<Variable, AggregateValue>();
        groups.set("undefined", groupToUpdate);
        for (const [variable, aggExpr] of Object.entries(operation.aggregatingExpressions)) {
          this.initializeGroup(aggExpr, variable, groupToUpdate);
        }
      }

      for (const [_, aggrResults] of groups) {
        if (aggrResults) {
          const bindings: Bindings<BindingValue> = {};
          for (const [variable, aggResult] of aggrResults) {
            const result = aggResult.finalize();
            if ("errorType" in result) continue;
            bindings[variable] = this.getBinding(result.term);
          }
          yield inputContext.addBindings(bindings);
        }
      }
    }
  }

  /**
   *  @DECISION if a variable should be in the projection but is not bound in
   *            a row of results, it will _not_ be included in the yielded row
   *            of results. (The alternative would've been to give the variable
   *            an explicit value of undefined.) This simplifies the
   *            implementation of sparql-results+json serialisation and also
   *            simplifies working with the bindings.
   *
   * @DECISION  because of the way we do scoping, we don't need a project operation
   */

  async *executeDistinct(
    operation: Distinct,
    resultContexts: ResultContexts<BindingValue>,
    queryContext: QueryContext,
  ): AsyncGenerator<ResultContext<BindingValue>> {
    /**
     * @DECISION: We're keeping a hash of all returned bindings in memory for each outer context. This may result for speedy-hdt
     *            in memory issues. For now, we consider this acceptable.
     *            If this results in memory issues for e.g. speedy-hdt at a later moment in time, we can always
     *            decide to make the `executeDistinct` configurable via a callback
     *            See https://issues.triply.cc/issues/7173
     *            Notice that we follow the same approach in fillOutConstructTemplate() of Engine.ts .
     *            If this approach causes memory issues in speedy-hdt, we might have to make changes
     *            in this function too.
     */

    for await (const inContext of resultContexts) {
      const processedBindings = new Set<string>();
      for await (const context of this.executeOperation(operation.inputOperation, [inContext], queryContext)) {
        const hasher = createHash("md5");
        const bindingNameAndTermIds = await Promise.all(
          operation.variables.map(async (distinctVar) => {
            const binding = context.bindings[distinctVar];
            let term: Term | undefined;
            if (binding) {
              term = await this.getTerm(binding);
            }
            return `${distinctVar}#${term?.id}`;
          }),
        );
        log("sparql:distinct", "%D", bindingNameAndTermIds);
        bindingNameAndTermIds.forEach((bindingNameAndTermId) => hasher.update(bindingNameAndTermId));
        const hash = hasher.digest("hex");
        if (processedBindings.has(hash)) {
          log("sparql:distinct", "duplicate");
          continue;
        }
        log("sparql:distinct", "distinct");
        processedBindings.add(hash);
        yield context;
      }
    }
  }

  async *executeSlice(operation: Slice, outsideContexts: ResultContexts<BindingValue>, queryContext: QueryContext) {
    const emptyContexts = initialResultContext();

    async function* doSlice(executor: Executor<BindingValue>) {
      // the `LIMIT 0` case should be handled during translation, so we don't
      // have to worry about it in this function.
      let rowCount = 0;
      for await (const context of executor.executeOperation(operation.inputOperation, emptyContexts, queryContext)) {
        rowCount++;
        if (rowCount <= operation.offset) {
          log("sparql:slice:offset", "skipping a context");
          continue;
        }
        log("sparql:slice:limit", "yielding context", rowCount);
        yield context;
        if (operation.limit !== undefined && rowCount >= operation.offset + operation.limit) {
          log(
            "sparql:slice:limit",
            "breaking because i=%D, offset=%D and limit=%D",
            rowCount,
            operation.offset,
            operation.limit,
          );
          break;
        }
      }
    }

    if (!operation.loadIntoMemory) {
      log("sparql:slice", "Streaming through subquery results");
      // this case should only happen when we're the outermost query level.
      // this means that we should always get a single input result context,
      // and that input result context should be the empty context.
      for await (const context of outsideContexts) {
        if (!deepEqual(emptyContexts[0], context))
          throw new FatalError(
            "Expected an empty input result context. Please contact a developer. Got " + JSON.stringify(context),
          );
        yield* doSlice(this);
      }
      return;
    }

    log("sparql:slice", "Loading all subquery results into memory");
    // now we must execute an in-memory join...
    // to protect ourselves from going OOM, we set an arbitrary (but really
    // high) max number of results. We expect subselects with a slice to only
    // have up to ~100 results (because it would be really weird to limit your
    // subquery anyway...). However, this assumption is wrong! See
    // https://issues.triply.cc/issues/7926
    const insideContexts = [];
    for await (const element of doSlice(this)) {
      if (insideContexts.length >= MAX_RESULTS_IN_MEMORY)
        throw new UnsupportedError(
          `A LIMIT larger than ${MAX_RESULTS_IN_MEMORY} isn't supported for sub-queries. Use a lower limit, or limit the outer-most query.`,
        );
      insideContexts.push(element);
    }
    for await (const outsideContext of outsideContexts) {
      for (const insideContext of insideContexts) {
        // because a subquery always has a project, we expect the number of
        // bound variables in the subquery to be smaller than the number of
        // bound variables coming from the `outsideContexts`
        let isCompatible = true;
        for (const [variable, insideBinding] of Object.entries(insideContext.bindings)) {
          const outsideBinding = outsideContext.bindings[variable];
          if (
            outsideBinding !== undefined &&
            !(await this.getTerm(insideBinding!)).equals(await this.getTerm(outsideBinding))
          ) {
            isCompatible = false;
            break;
          }
        }
        // If a variable is bound in both contexts, the argument to `addBinding`
        // "wins". We want this to be `outsideContext.bindings`, because that'll
        // live longest and therefore the binding values will acquire most information.
        if (isCompatible) yield outsideContext.addBindings(insideContext.bindings);
      }
    }
  }

  async *executeService(
    operation: Service,
    resultContexts: ResultContexts<BindingValue>,
    queryContext: QueryContext,
  ): AsyncGenerator<ResultContext<BindingValue>> {
    for await (const context of resultContexts) {
      /**
       * For each resultContext, add the bindings in the query and the endpoint (if it was initially a variable)
       * @DECISION
       * Even though the spec is talking about interplay between VALUES and SERVICE,
       * see https://www.w3.org/TR/sparql11-federated-query/#values, we used instead another approach with injectInPlace().
       * One risky part of choosing the latter approach is that we don't take care of scoping,
       * but this should have already been taken care of during the scoping part of translation.
       */

      const { endpoint, query } = await this.addBindingsInServiceQuery(
        operation.runTimeInformation,
        context,
        queryContext,
      );

      /**
       * With this information , make the request and get back bindings.
       */
      const bindings = sendSparqlSelectRequest({
        endpoint: typeof endpoint === "string" ? endpoint : endpoint.value,
        query: query,
      });

      /**
       * Yield the bindings added to the resultContext's bindings.
       * If iteration leads to an error, but the silent option is true
       * then silence the error and return the context.
       */
      try {
        for await (const binding of bindings) {
          yield context.addBindings(mapValues(binding, (term) => this.getBinding(term as NonNullable<typeof term>)));
        }
      } catch (e) {
        if (!operation.silent) throw e;
        yield context;
      }
    }
  }

  async addBindingsInServiceQuery(
    runTimeInfo: serviceRunTimeInfo,
    context: ResultContext<BindingValue>,
    queryContext: QueryContext,
  ) {
    runTimeInfo.query.base = queryContext.baseIri;

    /**
     * If we do not have resultContexts, then we just return the operation's runTimeInfo unchanged.
     */
    if (Object.entries(context.bindings).length < 1) return runTimeInfo;

    let runTimeInformationMutable = cloneDeep(runTimeInfo);

    const variablesDef: VariableConfig[] = [];
    const variableValues: {
      [variableName: string]: string | undefined;
    } = {};

    for (let [variable, binding] of Object.entries(context.bindings)) {
      if (binding === undefined) continue;
      const termOfBinding = await this.getTerm(binding);

      // Now if it's a blanknode, we don't pass bindings. Should be fixed in #7576
      if (termOfBinding.termType !== "BlankNode") {
        variablesDef.push({ name: variable, termType: termOfBinding.termType });
        variableValues[variable] = termOfBinding.value;
      }
      /**
       * If the endpoint is coming from a binding, we have to pass the value of the binding to the endpoint.
       */

      if (typeof runTimeInformationMutable.endpoint === "string" && variable === runTimeInformationMutable.endpoint) {
        if (termOfBinding.termType === "Literal" || termOfBinding.termType === "BlankNode")
          throw new SparqlError("Service doesn't have the correct type of value: it can only be an IRI.");
        runTimeInformationMutable = { ...runTimeInformationMutable, endpoint: termOfBinding };
      }
    }

    injectInPlace(runTimeInformationMutable.query, {
      variableDefinitions: variablesDef,
      variableValues: variableValues,
      queryString: "", // Original query string is used for custom pagination purposes in tdb. Not used by our engine, so setting to empty string
    });
    return runTimeInformationMutable;
  }

  async *executeInlineData(
    operation: InlineData,
    resultContexts: ResultContexts<BindingValue>,
    queryContext: QueryContext,
  ): AsyncGenerator<ResultContext<BindingValue>> {
    // Convert all `Term`s to `BindingValue`s.
    const dataBindingses = operation.values.map((row) => mapValues(row, (term) => this.getBinding(term!)));
    for await (const context of resultContexts) {
      log("sparql:InlineData", "context");
      for (const [terms, bindings] of zip(operation.values, dataBindingses)) {
        // We know the arrays have the same length
        if (!terms || !bindings) throw new FatalError("terms and bindings should both be defined.");
        log("sparql:InlineData", "row: %D", terms);

        // We should make sure the rows are compatible
        let allVariablesAreCompatible = true;
        for (const [variable, term] of Object.entries(terms)) {
          // if the variable wasn't bound in the VALUES,
          // it is always compatible. Note that this is a theoretic case
          // because all the unbound variables should not even be mentioned in
          // the `terms` or `bindings`.
          if (!term) continue;
          const binding = context.bindings[variable];
          if (!binding) continue; // this is not a theoretical case
          // we're using `equals` here and not our own implementation of
          // RDFterm-equal, because we don't want to be precise about type
          // errors: a Join just fails if we can't prove equality.
          if (!(await this.getTerm(binding)).equals(term)) {
            allVariablesAreCompatible = false;
            break;
          }
        }

        if (allVariablesAreCompatible) {
          const newContext = context.addBindings(bindings);
          log("sparql:InlineData", "yielding context %D", newContext);
          yield newContext;
        } // else: drop this row
      }
    }
  }

  /**
   * A recursive expression evaluator. Given an expression and bindings, it
   * will recursively evaluate each sub-expression until only a value remains,
   * or an error is thrown.
   *
   * @param expr      An expression to be evaluated.
   * @param resultContext   A single context to be used when evaluating the expression.
   *
   * @returns any error that occurred during evaluation, or the result of evaluation
   */
  async evaluateExpression(
    expr: Expression,
    resultContext: ResultContext<BindingValue>,
    queryContext: QueryContext,
  ): Promise<EvaluationResult> {
    // See also a summary of some generic rules of (filter) evaluation here:
    // - https://www.w3.org/TR/sparql11-query/#evaluation
    // - https://www.w3.org/TR/sparql11-query/#invocation
    // Notice that these don't seem to be about "functional forms" and only
    // about "functions"
    switch (expr.expressionType) {
      case "Variable":
        return this.evaluateVariable(expr, resultContext, queryContext);
      case "Term":
        return { evaluationResultType: "value", term: expr.term };
      case "Exists":
        // https://www.w3.org/TR/sparql11-query/#func-filter-exists
        for await (const _ignored of this.executeOperation(expr.operation, [resultContext], queryContext)) {
          return TRUE;
        }
        return FALSE;

      case "Operation": // https://issues.triply.cc/issues/7895
        // > For SELECT queries, the function's return value is the binding of
        // > the (single) result variable of the first solution in the result
        // > set. Since all other bindings will be ignored, such SELECT queries
        // > should only return at most one solution. If the result variable is
        // > unbound, then the function generates a SPARQL error.
        // from: https://www.w3.org/TR/shacl-af/#SPARQLFunction

        // @DECISION  we're not checking whether the function returns any more
        //            results, because the spec is unclear about what should
        //            happen if it does.
        const outputBindingValue = (await next(this.executeOperation(expr.operation, [resultContext], queryContext)))
          ?.bindings[expr.resultVariable];
        return outputBindingValue
          ? {
              evaluationResultType: "value",
              term: await this.getTerm(outputBindingValue),
            }
          : { evaluationResultType: "error", errorType: "UnboundVariableError", variable: expr.resultVariable };

      /**
       *  @DECISION Bound requires a variable and not an expression and it
       *   cannot be used within an AggregateExpression. Change has been made
       *   to support Bound as a NonAggregateLeaf and not part of
       *   GenericFunctionCall
       */
      case "Bound":
        const binding = resultContext.bindings[expr.variable];
        return binding === undefined ? FALSE : TRUE;
      // Section 17.4: https://www.w3.org/TR/sparql11-query/#SparqlOps
      case "FunctionCall":
        switch (expr.function) {
          // Functional forms https://www.w3.org/TR/sparql11-query/#func-forms
          // Section 17.4.1
          case "IF":
            const ebv = effectiveBooleanValue(
              await this.evaluateExpression(expr.expressions[0], resultContext, queryContext),
            );
            if (typeof ebv !== "boolean") return ebv;
            return ebv
              ? this.evaluateExpression(expr.expressions[1], resultContext, queryContext)
              : this.evaluateExpression(expr.expressions[2], resultContext, queryContext);
          case "COALESCE":
            /**
             * @DECISION Coalesce will evaluate subsequent expressions only if current expression
             * does not evaluate to an error */
            for (const expression of expr.expressions) {
              const result = await this.evaluateExpression(expression, resultContext, queryContext);
              if (result.evaluationResultType !== "error") return result;
            }
            return { evaluationResultType: "error", errorType: "CoalesceError" } as CoalesceError;
          case "!":
            const value = effectiveBooleanValue(
              await this.evaluateExpression(expr.expressions[0], resultContext, queryContext),
            );
            if (typeof value !== "boolean") return value;
            return value ? FALSE : TRUE;
          // Truth Table for the logical-and & logical-or : https://www.w3.org/TR/sparql11-query/#evaluation
          case "||":
            /**
             * @DECISION Early exit if left expression evaluates to a true
             */
            const ebvleft = effectiveBooleanValue(
              await this.evaluateExpression(expr.expressions[0], resultContext, queryContext),
            );
            if (ebvleft === true) return TRUE;
            const ebvright = effectiveBooleanValue(
              await this.evaluateExpression(expr.expressions[1], resultContext, queryContext),
            );
            if (ebvright === true) return TRUE;
            if (typeof ebvleft === "object") return ebvleft;
            if (typeof ebvright === "object") return ebvright;
            return FALSE;
          case "&&":
            /**
             * @DECISION Early exit if left expression evaluates to a false
             */
            const ebvl = effectiveBooleanValue(
              await this.evaluateExpression(expr.expressions[0], resultContext, queryContext),
            );
            if (ebvl === false) return FALSE;
            const ebvr = effectiveBooleanValue(
              await this.evaluateExpression(expr.expressions[1], resultContext, queryContext),
            );
            if (ebvr === false) return FALSE;
            if (typeof ebvl === "object") return ebvl;
            if (typeof ebvr === "object") return ebvr;
            return TRUE;
          case "=": // https://www.w3.org/TR/sparql11-query/#func-RDFterm-equal
          case "sameTerm": // https://www.w3.org/TR/sparql11-query/#func-sameTerm
            const evalleft = await this.evaluateExpression(expr.expressions[0], resultContext, queryContext);
            if (evalleft.evaluationResultType === "error") return evalleft;
            const evalright = await this.evaluateExpression(expr.expressions[1], resultContext, queryContext);
            if (evalright.evaluationResultType === "error") return evalright;
            // If the termType is different return False
            if (evalleft.term.termType !== evalright.term.termType) return FALSE;
            // Handle RDF-Term Equal conditions
            if (evalleft.term.termType === "Literal" && evalright.term.termType === "Literal") {
              // If datatype does not match
              if (evalleft.term.datatype.value !== evalright.term.datatype.value) return FALSE;
              // If language does not match
              if (evalleft.term.language !== evalright.term.language) return FALSE;
              // If datatype is equal and value is equal
              if (evalleft.term.value === evalright.term.value) return TRUE;
              // If datatype is equal but value is not, check if the datatype is supported
              // Notice that "supported" means that we canonicalized it:
              // that's the only case where we can be sure that different lexical forms
              // also mean different values.
              if (isRecognized(evalleft.term.datatype)) return FALSE;
              // Error for unsupported datatype (for `=`)
              return expr.function === "=" ? { evaluationResultType: "error", errorType: "RDFEqualTypeError" } : FALSE;
            }
            // For NamedNode and BlankNode check for the equality of the values
            return evalleft.term.value === evalright.term.value ? TRUE : FALSE;
          case "<":
            const first = await this.evaluateExpression(expr.expressions[0], resultContext, queryContext);
            const second = await this.evaluateExpression(expr.expressions[1], resultContext, queryContext);
            return lessThan(first, second);
          default:
            // Section 17.2: https://www.w3.org/TR/sparql11-query/#evaluation
            // > Any expression other than logical-or (||) or logical-and (&&)
            // > that encounters an error will produce that error.

            // Section 17.2.1: https://www.w3.org/TR/sparql11-query/#invocation
            // > SPARQL defines a syntax for invoking functions on a list of
            // > arguments. Unless otherwise noted, these are invoked as follows:
            // > - Argument expressions are evaluated, producing argument
            // >   values. The order of argument evaluation is not defined.
            // > - Numeric arguments are promoted as necessary to fit the
            // >   expected types for that function or operator.
            // > - The function or operator is invoked on the argument values.
            // >
            // > If any of these steps fails, the invocation generates an
            // > error. The effects of errors are defined in Filter
            // > Evaluation.
            // >
            // > There are also "functional forms" which have different
            // > evaluation rules to functions as specified by each such
            // > form.
            const possiblyErrorValues = await Promise.all(
              expr.expressions.map(async (expression) =>
                this.evaluateExpression(expression, resultContext, queryContext),
              ),
            );
            return this.evaluateFunctionalCall(possiblyErrorValues, expr.function, queryContext);
        }
    }
  }

  evaluateFunctionalCall(
    allValues: EvaluationResult[],
    functionName: StandardFunctionCall,
    queryContext?: QueryContext,
  ): EvaluationResult {
    const terms: Term[] = [];
    for (const value of allValues) {
      if (value.evaluationResultType === "error") return value;
      terms.push(value.term);
    }
    switch (functionName) {
      case "isIRI": // https://www.w3.org/TR/sparql11-query/#func-isIRI
        return terms[0].termType === "NamedNode" ? TRUE : FALSE;
      case "isBlank": // https://www.w3.org/TR/sparql11-query/#func-isBlank
        return terms[0].termType === "BlankNode" ? TRUE : FALSE;
      case "isLiteral": // https://www.w3.org/TR/sparql11-query/#func-isLiteral
        return terms[0].termType === "Literal" ? TRUE : FALSE;
      case "isNumeric": // https://www.w3.org/TR/sparql11-query/#func-isNumeric
        return terms[0].termType === "Literal" && validators.numericDatatype(terms[0].datatype) ? TRUE : FALSE;
      case "STR": // https://www.w3.org/TR/sparql11-query/#func-str
        return str(terms);
      case "STRLEN":
        return strlen(terms);
      case "SUBSTR":
        return substr(terms);
      case "UCASE":
        return ucase(terms);
      case "LCASE":
        return lcase(terms);
      case "STRSTARTS":
        return strstarts(terms);
      case "STRENDS":
        return strends(terms);
      case "CONTAINS":
        return contains(terms);
      case "CONCAT":
        return concat(terms);
      case "LANG":
        return lang(terms);
      case XPATH_FUNCTIONS.LANG:
        const langResultAsboolean = effectiveBooleanValue(lang(terms));
        if (typeof langResultAsboolean !== "boolean") return langResultAsboolean;
        return langResultAsboolean ? TRUE : FALSE;
      case "LANGMATCHES":
        return langmatches(terms);
      case "STRBEFORE":
        return strbefore(terms);
      case "STRAFTER":
        return strafter(terms);
      case "ENCODE_FOR_URI":
        return encode_for_uri(terms);
      case XPATH_FUNCTIONS.COMPARE:
        return compare(terms);
      case XPATH_FUNCTIONS.ENCODE_FOR_URI:
        return encode_for_uri(terms, "useURIComponent");
      case "REGEX":
        return regex(terms);
      case "REPLACE":
        return replace(terms);
      case "STRDT":
        return strdt(terms);
      case "STRLANG":
        return strlang(terms);
      case "IRI":
        return iri(terms, queryContext!.baseIri);
      case "DATATYPE":
        return datatype(terms);
      case "NOW":
        /**
         *  Returns an xsd:dateTime value for the current query execution.
         *
         *  All calls to this function in any one query execution must return the same
         *  value. The exact moment returned is not specified.
         *
         *  https://www.w3.org/TR/sparql11-query/#func-now
         */
        return {
          evaluationResultType: "value",
          term: dataFactory.literal(queryContext!.now.toISOString(), DATA_TYPES.XSD_DATE_TIME),
        };
      case "YEAR":
        return year(terms);
      case "MONTH":
        return month(terms);
      case "DAY":
        return day(terms);
      case "HOURS":
        return hours(terms);
      case "MINUTES":
        return minutes(terms);
      case "SECONDS":
        return seconds(terms);
      case "TIMEZONE":
        return timezone(terms);
      case "TZ":
        return tz(terms);
      case "ABS":
        return abs(terms);
      case "CEIL":
        return ceil(terms);
      case "FLOOR":
        return floor(terms);
      case "ROUND":
        return round(terms);
      case XPATH_FUNCTIONS.ROUND:
        /**
         * xpath round can possibly take 2 arguments
         */
        return round(terms);
      case DATA_TYPES.XSD_BOOLEAN.value:
        return xsdboolean(terms);
      case DATA_TYPES.XSD_STRING.value:
        return xsdstring(terms);
      case DATA_TYPES.XSD_DOUBLE.value:
        return xsddouble(terms);
      case DATA_TYPES.XSD_FLOAT.value:
        return xsdfloat(terms);
      case DATA_TYPES.XSD_DECIMAL.value:
        return xsddecimal(terms);
      case DATA_TYPES.XSD_INTEGER.value:
        return xsdinteger(terms);
      case DATA_TYPES.XSD_INT.value:
        return xsdint(terms);
      case DATA_TYPES.XSD_LONG.value:
        return xsdlong(terms);
      case DATA_TYPES.XSD_DATE_TIME.value:
        return xsddatetime(terms);
      case DATA_TYPES.XSD_DATE.value:
        return xsddate(terms);
      case DATA_TYPES.XSD_G_YEAR.value:
        return xsdgYear(terms);
      case "+":
        const outputDataType = validateAndGetNumericDataType(terms[0], terms[1]);
        if ("errorType" in outputDataType) return outputDataType;
        return newLiteral(
          decimalToRoundedString(canonicalToNumber(terms[0].value) + canonicalToNumber(terms[1].value)),
          outputDataType,
        );
      case "*":
        const newDataType = validateAndGetNumericDataType(terms[0], terms[1]);
        if ("errorType" in newDataType) return newDataType;
        return newLiteral(
          decimalToRoundedString(canonicalToNumber(terms[0].value) * canonicalToNumber(terms[1].value)),
          newDataType,
        );
      case "-":
        const outDataType = validateAndGetNumericDataType(terms[0], terms[1]);
        if ("errorType" in outDataType) return outDataType;
        return newLiteral(
          decimalToRoundedString(canonicalToNumber(terms[0].value) - canonicalToNumber(terms[1].value)),
          outDataType,
        );
      case "/":
        const numericDataType = validateAndGetNumericDataType(terms[0], terms[1]);
        if ("errorType" in numericDataType) return numericDataType;
        let divisionDataType: NumericDataType | InvalidArgumentTypes;
        // From the spec, if the two arguments are of type XSD_INTEGER, then the resulting data type is DECIMAL else type promote
        // https://www.w3.org/TR/xpath-functions/#func-numeric-divide
        divisionDataType =
          numericDataType.value === DATA_TYPES.XSD_INTEGER.value ? DATA_TYPES.XSD_DECIMAL : numericDataType;
        if ("errorType" in divisionDataType) return divisionDataType as any;
        return newLiteral(
          decimalToRoundedString(canonicalToNumber(terms[0].value) / canonicalToNumber(terms[1].value)),
          divisionDataType,
        );
      case "BNODE":
        return bnode(terms);
      case XPATH_FUNCTIONS.BOOLEAN:
        const returnFromEVB = effectiveBooleanValueOfTerm(terms[0]);
        if (typeof returnFromEVB !== "boolean") return returnFromEVB;
        return returnFromEVB ? TRUE : FALSE;
      case "MD5":
        return hashStrings(terms, "md5");
      case "SHA1":
        return hashStrings(terms, "sha1");
      case "SHA256":
        return hashStrings(terms, "sha256");
      case "SHA384":
        return hashStrings(terms, "sha384");
      case "SHA512":
        return hashStrings(terms, "sha512");
      case "UUID":
        return {
          evaluationResultType: "value",
          term: dataFactory.namedNode("urn:uuid:" + randomUUID()),
        };
      case "STRUUID":
        // @DECISION - We do not have simple literals within speedy, so considering the datatype as an XSD_STRING to ensure compatibility
        return newLiteral(randomUUID(), DATA_TYPES.XSD_STRING);
      case "RAND":
        // Rounding the decimal ensures no underflow/overflow error
        return newLiteral(decimalToRoundedString(Math.random()), DATA_TYPES.XSD_DOUBLE);
      case GEO_FUNCTIONS.PROJECT.value:
      case GEO_FUNCTIONS.TRANSFORM.value:
        const wktLiteral = terms[0];
        const crs = terms.length === 1 ? dataFactory.namedNode(DEFAULT_CRS) : terms[1];
        if (!validators.literal(wktLiteral) || !validators.namedNode(crs)) return invalidArgumentTypesError;

        if (wktLiteral.datatype.value !== WktLiteralDatatype) return invalidArgumentTypesError;
        if (!isSupportedCrs(crs.value)) return invalidArgumentTypesError;

        const geometry = wktLexicalToValue(wktLiteral.value);
        if (!isSupportedCrs(geometry.crs)) return invalidArgumentTypesError;
        let transformedCoordinates = geoProject(geometry, crs.value);
        return newLiteral(
          valueToCanonical(transformedCoordinates, WktLiteralDatatype),
          dataFactory.namedNode(WktLiteralDatatype),
        );
      case GEO_FUNCTIONS.AREA.value:
      case GEO_FUNCTIONS.METRIC_AREA.value:
        const geoLiteral = terms[0];
        const unit = terms.length === 1 ? dataFactory.namedNode(DEFAULT_UNIT) : terms[1];

        if (!validators.literal(geoLiteral) || !validators.namedNode(unit)) return invalidArgumentTypesError;
        if (geoLiteral.datatype.value !== WktLiteralDatatype) return invalidArgumentTypesError;
        if (!isSupportedAreaUnit(unit.value)) return invalidArgumentTypesError;

        const polygon = wktLexicalToValue(geoLiteral.value);
        return newLiteral(geoArea(polygon, unit.value).toString(), DATA_TYPES.XSD_DOUBLE);
    }
  }

  async evaluateVariable(
    expr: VariableExpression,
    resultContext: ResultContext<BindingValue>,
    queryContext: QueryContext,
  ): Promise<EvaluationResult> {
    const binding = resultContext.bindings[expr.variable];
    if (binding === undefined || expr.variable === UNBOUND_VARIABLE_NAME)
      return {
        evaluationResultType: "error",
        errorType: "UnboundVariableError",
        variable: expr.variable,
      };
    return {
      evaluationResultType: "value",
      term: await this.getTerm(binding),
    };
  }
}
