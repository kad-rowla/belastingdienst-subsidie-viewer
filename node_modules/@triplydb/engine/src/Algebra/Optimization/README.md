# What is going on in the optimization of Algebra?

The optimization of a [Sparql Algebra](https://www.w3.org/TR/sparql11-query/#sparqlAlgebra) involves the following steps

- Generation of a Query Plan/Semantically equivalent Algebra: This step involves creating all valid semantically equivalent Algebras that when executed produce the same set of bindings as the original Algebra.

- Estimating the Complexity of Query Plan/Algebra: For each Algebra (or) Query plan from the above step, we employ `estimation` techniques to calculate the amount of time it will take to execute it.

- Choosing an optimal time-consuming Algebra: The least time-consuming Algebra is chosen as the `OptimizedAlgebra`.

## How to generate semantically equivalent Algebra

To generate all semantically equivalent algebra, the operations from the original query are re-ordered to produce a new Algebra.

(e.g)

**Original Query**

```
Select * {
    ?s ?p ?q .
    ?s :p ?o
}
```

**Algebra of the original Query**

```
{
    operationType: "Join",
    id: "0",
    inputOperations: [
        {
        operationType: "TriplePattern",
        id: "0.0",
        pattern: ["s", "p", "q"],
        },
        {
        operationType: "TriplePattern",
        id: "0.1",
        pattern: ["s", i(":p"), "o"],
        },
    ],
}
```

**Algebra after Re-order**

```
{
    operationType: "Join",
    id: "0",
    inputOperations: [
        {
        operationType: "TriplePattern",
        id: "0.1",
        pattern: ["s", i(":p"), "o"],
        },
        {
        operationType: "TriplePattern",
        id: "0.0",
        pattern: ["s", "p", "q"],
        }
    ],
}
```

_Both the above Algebra produces the same set of bindings. This might not always be the case as the order of Operation can affect the result. To ensure semantic equivalence, the following algorithm is employed recursively_

- For all [Operations](packages/engine/src/Algebra/Operation.ts), separate them into the respective types, namely NoAry (BaseOperation), UnaryOperation, BinaryOperation, and NAryOperation.

- Convert the NAryOperation into a list of Operations.

- Similarly, flatten a UnaryOperation till a NoAry/BinaryOperation is encountered. Steps 2 & 3 ensure that the Algebra is converted to a list of Operations that can now be freely re-ordered.

- Handle BinaryOperation carefully as the order of the child for BinaryOperation is important and re-ordering them wrongly produces non-equivalent algebras.

- Recursively split the Operation into a list of operations (we refer to this as `ConjunctionOfDisjunction`).

- For each of these valid lists of operations, re-order their position to create a new Algebra.

- Whenever 2 operations from the list are re-ordered, a new Algebra is created. Since this can lead to N! (N=number of operations) Algebra, it can blow up very quickly. To prevent this from happening, we use heuristic methods to reduce the number of re-orders. For more information, check `getConnectedOperations()` in `optimize-reorder.ts`

_Note: Converting the `Operation` object to a list of `Operation` is an algorithmic decision for easy re-ordering_

## Estimating the Complexity of the Algebra

Once a new Algebra is available, the complexity can be estimated. This is a _relative estimate_ of the original Algebra and involves certain heuristics to calculate 2 properties.

- SpaceEstimate - This refers to the 'possible' bindings that will be produced by an operation

- TimeEstimate - This refers to the time it will take to 'query' + 'process' + 'yield' all the possible 'bindings' for the operation. This is an **abstract scale** where we count fetching a triple from the HDT document as unit time.

Lower the Estimate (time (or) space), it indicates the speed (or) efficiency of the algebra compared to the other re-ordered Algebras.

Note: TimeEstimate does not include estimation of hardware restrictions like 'available memory', 'clock-speed' etc to keep the estimation light.

Depending on the type of Operation, the individual score/estimate is aggregated to obtain the final cost of the Algebra. 'Cost' here refers to the TimeEstimate as that is the focus of this optimization.

## Estimate the triple-pattern operation

Estimating the triple pattern, or BGP is done by using the statistics of the graph. Each graph contains equivalent statistics that include, `distinct subject`, `distinct object` given a predicate, and `std-dev` for a given object and subject. These are helpful to estimate the complexity of a given BGP/TriplePattern.

In the table below, we see the different types of TriplePattern based on the boundedness of the variable and how the estimation is carried out.

| Type of Triple-Pattern                        | Example       | Calculated Complexity                                          | Explanation                                                                                                                                                                              |
| --------------------------------------------- | ------------- | -------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `Const Const Const`                           | `a:s a:p a:o` | `timeEstimate = 0.1`, `SpaceEstimate = 1`                      | This represents the simple case where we know all three patterns. It can either bind to 1 result or none, so we assign the cheapest timeEstimate of 0.1                                  |
| `Const\|BoundedVar Const Unbounded`           | `a:s a:p ?o`  | `timeEstimate = spaceEstimate = SubjectBranchingFactor`        | If the predicate is known, and the subject is a const (or) bounded variable but the object is unbounded, the estimate is the SubjectBranchingFactor                                      |
| `UnboundedVar Const Const\|BoundedVar`        | `?s a:p a:o`  | `timeEstimate = spaceEstimate = ObjectBranchingFactor`         | If the predicate is known and the object is a const (or) bounded variable, the estimate is the ObjectBranchingFactor                                                                     |
| `UnboundedVar Const UnboundedVar`             | `?s a:p ?o`   | `timeEstimate = spaceEstimate = numOfTriplesMatchingPredicate` | If the predicate is known, but both the subject and object are unknown, the estimate is all triples that contain that predicate                                                          |
| `BoundedVar\|Const unboundedVar UnboundedVar` | `a:s ?p ?o`   | `timeEstimate = spaceEstimate = #triples/distinct subjects`    | If the predicate is unknown, but the subject known, the triples that will be matched is estimated as the total triples to the number of distinct subjects. This is a rough estimate only |
| `UnboundedVar unboundedVar BoundedVar\|Const` | `?s ?p a:o`   | `timeEstimate = spaceEstimate = #triples/distinct objects`     | If the predicate is unknown, but the subject known, the triples that will be matched is estimated as the total triples to the number of distinct objects.                                |
| `All Remaining Cases`                         | `All`         | `timeEstimate = spaceEstimate = #triples matching the query`   | The HDT provides a fast queryable interface that can 'estimate' the number of triples that match a query. This is used to determine the cost for all the remaining scenarios             |

### Glossary

**Const** - A known IRI/NamedNode in either subject/object/predicate position

**BoundedVar** - A variable that is bounded by some operation before encountering this triple-pattern

**UnboundedVar** - A variable that is encountered for the first time.

**BranchingFactor** - A branch factor is a good estimate of how complex the triple pattern is. The higher the branching factor, lot of triples satisfy the given pattern.
It is merely the ratio of all matching triples(with (or) without a matching predicate) to the number of **distinct** subject (or) objects (also referred to as leaf).

The branching factor is a decimal from 1 to infinity, 1 means that there is only 1 subject/object that matches the requirement, while a branching factor of 100 means there are 100 possible subjects/objects that need to be traversed to get all matching triples.
