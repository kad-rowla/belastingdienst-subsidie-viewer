import { AsyncBindingsIterable, Executor, QueryOptions } from "./Execution.js";
import * as sparqljs from "sparqljs";
import log from "./Debugging.js";
import * as Terms from "@triplydb/data-factory/Terms.js";
import { Bindings, dataFactory, DEFAULT_BASE_IRI, Term } from "./constants.js";
import { BindingsResult, BooleanResult, DebugResult, QuadsResult } from "./QueryResults.js";
import { SparqlError, UnknownFunctionError, UnsupportedError } from "./Errors.js";
import { optimizeAlgebra } from "./Algebra/Optimization/optimize-reorder.js";
import { createHash } from "crypto";
import { Operation } from "./Algebra/Operation.js";
import { QueryContext } from "./QueryContext.js";
import { deplete } from "./Helpers.js";
import { scopeVariables } from "./Algebra/ASTtoAlgebra/variableScope.js";
import { rewriteDescribeQuery } from "./Algebra/ASTtoAlgebra/translationUtils.js";
import { parse } from "./Helpers.js";
import {
  ExtraTranslationInfo,
  TripleTemplates,
  operationFromScopedAst,
  templatesFromAst,
} from "./Algebra/ASTtoAlgebra/index.js";
import { getDataDefinedFunctionInfo, getPrefixes } from "./shaclSparqlFunctions.js";
import { optimizeAlgebraLight } from "./Algebra/Optimization/optimize-light.js";
import { BindingsType, SpecificationToBindings, validateAsyncBindingsIterable } from "./validateBindings.js";

const magicPrefix = "https://triplydb.com/Triply/sparql/id/value/";

type PrefixKey = "triply_disabletermvalidation" | "triply_optimize" | "triply_debugonly" | "triply_debugoncompletion";
type magicPrefixOptions = {
  optimize: boolean | undefined;
  disableTermValidation: boolean;
  debugOnly: boolean;
  debugOnCompletion: boolean;
};

export interface DebugInfo {
  /** First convertion to algebra from AST */
  operation?: Operation;
  /** If optimization is done then this variable holds the new Algebra */
  optimizedAlgebra?: Operation;
  /** If optimization is done, then this holds the estimatedComplexity */
  estimatedComplexity?: number;
  optimize?: boolean;
}

// We will return only 2 type of Results when debug is turned on, Bindings and Quads.
const DEBUG_QUERY_RESULT_TYPE = {
  SELECT: "bindings",
  CONSTRUCT: "quads",
  DESCRIBE: "quads",
  ASK: "bindings",
} as const satisfies {
  [queryType in sparqljs.Query["queryType"]]: (BindingsResult | QuadsResult)["type"];
};

type QueryResultType = {
  SELECT: BindingsResult;
  CONSTRUCT: QuadsResult;
  DESCRIBE: QuadsResult;
  ASK: BooleanResult;
};

export type QueryResult = QueryResultType[keyof QueryResultType];

/**
 * This Engine class connects the parser, AST translator, executor and serialization to create an end-to-end SPARQL
 * engine.
 */

/** Note: This engine includes only SPARQL queries, and not UPDATE */
export class QueryEngine {
  // The distinction between `unknown` and `any` is intentional:
  // we want to allow any executor as argument, but we don't want anyone to
  // be able to access the (not type-checked) BindingValue
  readonly executor: Executor<unknown>;
  readonly optimize: boolean;
  dataDefinedFunctions: ExtraTranslationInfo["dataDefinedFunctions"] = {};

  constructor(executor: Executor<any>, opts: Pick<QueryEngine, "optimize">) {
    this.executor = executor;
    this.optimize = opts.optimize;
  }

  public async select(query: string): Promise<BindingsResult>;
  public async select<B extends BindingsType>(
    query: string,
    bindingsType: B
  ): Promise<BindingsResult<SpecificationToBindings<B>>>;
  public async select<B extends BindingsType>(query: string, bindingsType?: B) {
    return this.query(query, { queryType: "SELECT", bindingsType: bindingsType ?? {} });
  }
  public async construct(query: string): Promise<QuadsResult> {
    return this.query(query, { queryType: "CONSTRUCT" });
  }
  public async describe(query: string): Promise<QuadsResult> {
    return this.query(query, { queryType: "DESCRIBE" });
  }
  public async ask(query: string): Promise<boolean> {
    return (await this.query(query, { queryType: "ASK" })).result();
  }

  public async query<Q extends sparqljs.Query["queryType"]>(
    query: string,
    options?: Omit<QueryOptions, "rdfDataset"> & { queryType?: Q }
  ): Promise<QueryResultType[Q]>;
  public async query<B extends BindingsType>(
    query: string,
    options?: Omit<QueryOptions, "rdfDataset"> & { queryType: "SELECT"; bindingsType: B }
  ): Promise<BindingsResult<SpecificationToBindings<B>>>;
  public async query(
    query: string,
    options?: Omit<QueryOptions, "rdfDataset"> & {
      queryType?: sparqljs.Query["queryType"];
      bindingsType?: BindingsType;
    }
  ): Promise<BindingsResult | QuadsResult | BooleanResult> {
    log("sparql:queryString", query);
    const ast = parse(query, { baseIri: options?.baseIri ?? DEFAULT_BASE_IRI });
    if (ast.type !== "query")
      throw new UnsupportedError("Only SELECT, CONSTRUCT, DESCRIBE and ASK queries are supported.");

    if (options?.queryType && ast.queryType !== options.queryType)
      throw new SparqlError(`Expected ${options.queryType} query, but got ${ast.queryType} query.`);

    return this.queryAst(ast, options);
  }

  public async queryAst<Q extends sparqljs.Query>(
    ast: Q,
    options?: Omit<QueryOptions, "rdfDataset">
  ): Promise<QueryResultType[Q["queryType"]]>;
  public async queryAst<B extends BindingsType>(
    ast: sparqljs.SelectQuery,
    options?: Omit<QueryOptions, "rdfDataset"> & { bindingsType: B }
  ): Promise<BindingsResult<SpecificationToBindings<B>>>;
  public async queryAst(
    ast: sparqljs.Query,
    options?: Omit<QueryOptions, "rdfDataset"> & { bindingsType?: BindingsType }
  ): Promise<BindingsResult | QuadsResult | BooleanResult> {
    let baseIri = ast.base ?? options?.baseIri ?? DEFAULT_BASE_IRI;
    const magicPrefixOptions = buildPrefixOptions(ast, options);
    const optimize = magicPrefixOptions.optimize ?? this.optimize;
    const isDebugFlagOn = magicPrefixOptions.debugOnly || magicPrefixOptions.debugOnCompletion;

    const rdfDataset = this.executor.getRdfDataset(ast.from);

    const updatedOptions = {
      abortSignal: options?.abortSignal,
      baseIri,
      rdfDataset,
      ...magicPrefixOptions,
    };
    const debugInfo: DebugInfo = { optimize };
    let executedQuery:
      | {
          queryContext: QueryContext;
          results: AsyncBindingsIterable;
        }
      | undefined;

    // Translate, optimize and execute the query
    const resultType = DEBUG_QUERY_RESULT_TYPE[ast.queryType];
    try {
      log("sparql:translate:ast", "Translating AST:\n%D", ast);

      if (ast.queryType === "DESCRIBE") ast = rewriteDescribeQuery(ast);
      ast = scopeVariables(ast);

      let operation = operationFromScopedAst(ast, {
        dataDefinedFunctions: this.dataDefinedFunctions,
        variablesToTranslateWithoutErrorChecking: new Set(),
        namedGraphs: rdfDataset.namedGraphs,
      });
      debugInfo.operation = operation;

      log("sparql:translate:algebra:unoptimized", "Resulting algebra:\n%D", operation);
      if (optimize) {
        // Perform light optimization
        const lightOptimization = optimizeAlgebraLight(operation);
        // This optimization doesn't need statistics, we will need to move it during ticket #7932
        const statistics = this.executor.getPredicateStatsAndGraphs();
        if (!statistics) {
          // SparqlError, as we want the user to know what is going on, and developers shouldn't see this as an error.
          throw new SparqlError("Unable to optimize this query, as we are missing statistics.");
        }
        const optimizationResult = await optimizeAlgebra(lightOptimization, statistics);
        debugInfo.optimizedAlgebra = operation = optimizationResult.operation;
        debugInfo.estimatedComplexity = optimizationResult.estimatedComplexity;

        log("sparql:translate:algebra:optimized", "Optimized algebra:\n%D", operation);
      }

      if (magicPrefixOptions.debugOnly) {
        return new DebugResult(resultType, debugInfo) as any;
      }

      // Perform query execution
      executedQuery = this.executor.query(operation, updatedOptions);
      if (updatedOptions?.debugOnCompletion) {
        // We will deplete the results to ensure that the queryContext counting is done properly.
        // Note that the result is not part of the binding that is returned from DebugResult, so no need to store the results in memory
        // We deplete this here to ensure that any SpeedyError is caught within the engine and handled properly when in debug mode.
        await deplete(executedQuery.results);
        // We are manually setting the type of the result here to satisfy the content-negotiator. As this is only an internal resultType, this satisfies the expected resultType
        return new DebugResult(resultType, debugInfo, executedQuery.queryContext) as any;
      }

      switch (ast.queryType) {
        case "SELECT":
          return new BindingsResult(
            options?.bindingsType
              ? validateAsyncBindingsIterable(executedQuery.results, options.bindingsType)
              : executedQuery.results,
            ast.variables.map((v) => ("variable" in v ? v.variable : v).value),
            executedQuery.queryContext
          );
        case "ASK":
          return new BooleanResult(executedQuery.results, executedQuery.queryContext);
        case "CONSTRUCT":
          return new QuadsResult(
            fillOutConstructTemplates(executedQuery.results, templatesFromAst(ast.template)),
            executedQuery.queryContext
          );
      }
    } catch (e) {
      const error = e as Error;
      if (isDebugFlagOn) {
        return executedQuery
          ? new DebugResult(resultType, debugInfo, executedQuery.queryContext, error)
          : (new DebugResult(resultType, debugInfo, undefined, error) as any);
      }
      throw e;
    }
  }

  async initializeShaclSparqlFunctions() {
    const prefixes = await getPrefixes(this);
    // > SHACL instances of sh:SPARQLFunction that are IRIs in a shapes graph
    // > are called SPARQL-based functions.
    // from: https://www.w3.org/TR/shacl-af/#SPARQLFunction
    //
    // > A node n in an RDF graph G is a SHACL instance of a SHACL class C in G
    // > if one of the SHACL types of n in G is C.
    // from: https://www.w3.org/TR/shacl/#dfn-shacl-instance
    //
    // > A node Sub in an RDF graph is a SHACL subclass of another node Super in
    // > the graph if there is a sequence of triples in the graph each with
    // > predicate rdfs:subClassOf such that the subject of the first triple is
    // > Sub, the object of the last triple is Super, and the object of each
    // > triple except the last is the subject of the next. If Sub is a SHACL
    // > subclass of Super in an RDF graph then Super is a SHACL superclass of
    // > Sub in the graph.
    // from: https://www.w3.org/TR/shacl/#dfn-shacl-superclass
    const results = await this.select(
      `
      PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
      PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
      PREFIX sh: <http://www.w3.org/ns/shacl#>
      SELECT * WHERE {
        ?f rdf:type/rdfs:subClassOf* sh:SPARQLFunction
      }
    `,
      { f: ["NamedNode", "BlankNode"] }
    );
    let queue: Terms.NamedNode[] = [];
    for await (const { f } of results) {
      // @DECISION silently filter out non-IRIs, since the spec says:
      // > SHACL instances of sh:SPARQLFunction that are IRIs in a shapes graph
      // > are called SPARQL-based functions.
      // from: https://www.w3.org/TR/shacl-af/#SPARQLFunction
      if (f.termType === "NamedNode") queue.push(f);
    }

    // Retry mechanism to make sure functions can reference each other.
    // See https://issues.triply.cc/issues/7895#NB-1
    // The idea is to try all functions in succession while ignoring any errors
    // related to using an unknown function (because those may be references to
    // as-of-yet unproessed functions). As long as we managed to process at
    // least one function, we'll try all the remaining ones again.
    let lastQueue: typeof queue;
    do {
      lastQueue = queue;
      queue = [];
      for (const functionNode of lastQueue) {
        try {
          this.dataDefinedFunctions[functionNode.value] = await getDataDefinedFunctionInfo(
            this,
            functionNode,
            prefixes
          );
        } catch (e) {
          if (e instanceof UnknownFunctionError) {
            queue.push(functionNode);
          } else throw e;
        }
      }
    } while (lastQueue.length > queue.length);
    if (queue.length)
      throw new UnsupportedError(
        "The following SHACL SPARQL functions are (mututally) recursive, which isn't supported: " +
          queue.map(({ id }) => id).join(" ")
      );
  }
}

const buildPrefixOptions = (ast: sparqljs.Query, options?: QueryOptions): magicPrefixOptions => {
  // Override query execution with magic query options.
  const disableTermValidation =
    getQueryOptionBoolean(ast, "triply_disabletermvalidation") ?? options?.disableTermValidation;
  // Setup the optimize variable here as an object to manipulate it later if needed
  const optimizationOptions = getQueryOptionBoolean(ast, "triply_optimize");

  let debugOnlyFlag = !!getQueryOptionBoolean(ast, "triply_debugonly");
  const debugOnCompletion = !!getQueryOptionBoolean(ast, "triply_debugoncompletion");
  // If both debugOnly and debugoncompletion is set, prioritize debugoncompletion
  if (debugOnlyFlag && debugOnCompletion) {
    debugOnlyFlag = false;
  }

  return {
    optimize: optimizationOptions,
    disableTermValidation: !!disableTermValidation,
    debugOnly: debugOnlyFlag,
    debugOnCompletion: debugOnCompletion,
  };
};

const getQueryOptionBoolean = (ast: sparqljs.SparqlQuery, prefixKey: PrefixKey) => {
  let value = ast.prefixes[prefixKey]?.split(magicPrefix)[1];
  if (!value) return undefined;
  value = value.toLocaleLowerCase();
  return value === "true" ? true : value === "false" ? false : undefined;
};

/**
 *  Create quads by applying a bunch of templates to every row of results.
 */
export function* fillOutTripleTemplates(
  bindings: Bindings<Term>,
  templates: TripleTemplates,
  mutable: { blankNodeCounter: number; hashedQuads: Set<string> },
  graph?: Terms.NamedNode
) {
  const aliasToBlankNode = new Map<string, Terms.BlankNode>();
  // Helper function for keeping track of blank nodes in the template, and translating them to blank nodes that we
  // generator ourselves with our own data factory.
  function getOrAddBlankNode(alias: string) {
    let blankNode = aliasToBlankNode.get(alias);
    if (!blankNode) {
      mutable.blankNodeCounter += 1;
      log("sparql:engine:construct:blankNodeCounter", "Blank node counter is :", mutable.blankNodeCounter);
      blankNode = dataFactory.blankNode(mutable.blankNodeCounter.toString());
      aliasToBlankNode.set(alias, blankNode);
    }
    return blankNode;
  }

  // Fill out the triple patters in the CONSTRUCT template, with bindings from the context.
  for (const triplePattern of templates) {
    // According to https://www.w3.org/TR/sparql11-query/#construct:
    //   If any such instantiation produces a triple containing an unbound variable or an illegal RDF construct,
    //   (...) then that triple is not included in the output RDF graph.
    // Because of this, we exclude unbound variables.
    let subject: Terms.NamedNode | Terms.BlankNode;
    let predicate: Terms.NamedNode;
    let object: Terms.NamedNode | Terms.BlankNode | Terms.Literal;
    if (typeof triplePattern.subject === "string") {
      // Subject is a variable
      const term = bindings[triplePattern.subject];
      if (!term) {
        log(
          "sparql:engine:construct:unboundSubject",
          "Unbound variable",
          triplePattern.subject,
          "in subject position."
        );
        continue; // Skip triple on unbound variable.
      }
      if (term.termType === "Literal") {
        log("sparql:engine:construct:illegalSubject", "Illegal literal", term, "in subject position.");
        continue; // Skip illegal literal in subject position.
      }
      subject = term;
    } else if (triplePattern.subject.termType === "BlankNode") {
      // Subject is a blank node
      subject = getOrAddBlankNode(triplePattern.subject.value);
    } else {
      // Subject is an IRI
      subject = triplePattern.subject;
    }

    if (typeof triplePattern.predicate === "string") {
      // Predicate is a variable
      const term = bindings[triplePattern.predicate];
      if (!term) {
        log(
          "sparql:engine:construct:unboundPredicate",
          "Unbound variable",
          triplePattern.predicate,
          "in predicate position."
        );
        continue; // Skip triple on unbound variable.
      }
      if (term.termType !== "NamedNode") {
        log("sparql:engine:construct:illegalPredicate", "Illegal term", term, "in predicate position.");
        continue; // Skip illegal term type in predicate position.
      }
      predicate = term;
    } else {
      // Predicate is an IRI
      predicate = triplePattern.predicate;
    }

    if (typeof triplePattern.object === "string") {
      // Object is a variable
      const term = bindings[triplePattern.object];
      if (!term) {
        log("sparql:engine:construct:unboundObject", "Unbound variable", triplePattern.object, "in object position.");
        continue; // Skip triple on unbound variable.
      }
      object = term;
    } else if (triplePattern.object.termType === "BlankNode") {
      object = getOrAddBlankNode(triplePattern.object.value);
    } else {
      // Object is an IRI or Literal
      object = triplePattern.object;
    }
    const quad = dataFactory.quad(subject, predicate, object, graph);
    const hash = createHash("md5").update(quad.id).digest("hex");
    if (mutable.hashedQuads.has(hash)) {
      continue;
    }

    // For very large results set (millions of quads), we'll reach the Set
    // size limit In that case, reset the set. We accept some (temporary)
    // duplicates as output This limit is not documented, and depends on the
    // runtime engine. A test on node 20 showed a max size of
    // 16-million-something.
    // See https://stackoverflow.com/a/72809580/1052020
    if (mutable.hashedQuads.size > 16_000_000) {
      mutable.hashedQuads.clear();
    }
    mutable.hashedQuads.add(hash);
    log("sparql:engine:quad", "Quad is: ", quad);
    yield quad;
  }
}
/**
 *  Create quads by applying a bunch of templates to every row of results.
 */
export async function* fillOutConstructTemplates(
  results: AsyncBindingsIterable,
  templates: TripleTemplates,
  graph?: Terms.NamedNode
) {
  const mutableState = {
    blankNodeCounter: 0,
    hashedQuads: new Set<string>(),
  };

  for await (const bindings of results) {
    /**
     *  We cannot have duplicate triples in a single RDF graph.
     *  For this reason, we keep track of the hashed quad ids
     *  and we return only quads that are unique.
     *
     *  Notice that we use the same approach as in
     *  executeDistinct function of Execution.ts .
     */
    yield* fillOutTripleTemplates(bindings, templates, mutableState, graph);
  }
}
