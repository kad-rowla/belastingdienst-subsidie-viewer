import { Etl } from "../../index.js";
import { addMwCallSiteToError, assertOneExtractorPerETL, md5OfArray } from "../../../utils/index.js";
import { XMLParser } from "fast-xml-parser";
import { assertIsObject } from "../../../utils/asserts.js";
import { castArray, floor, mapValues, sum, set as _set } from "lodash-es";
import fs from "fs-extra";
import { resolve } from "path";
import { millify } from "millify";
import pTimeout from "p-timeout";
import fetch from "cross-fetch";
import pReflect from "p-reflect";
const MILLISECONDS_IN_A_DAY = 1000 * 60 * 60 * 24;
import trimRecordFromSource from "./util/trimRecordFromSource.js";
import msTohoursMinutSeconds from "../../../utils/msTohms.js";
import { validatePaths } from "./fromXml.js";
import { matchFromRecord } from "./fromJson.js";
class OaiError extends Error {
    constructor({ error, extraText, url, }) {
        super(`Error response from OAI: [${error["@code"]}]` +
            (error["$text"] ? " " + error["$text"] : "") +
            extraText +
            " Tried to fetch " +
            url);
        this.error = error;
        this.extraText = extraText;
        this.url = url;
    }
}
/**
 * Read records from an open archive initiative API.
 *
 * See http://www.openarchives.org/OAI/openarchivesprotocol.html
 */
export default function fromOai(opts) {
    return addMwCallSiteToError(async function _fromOai(ctx, next) {
        assertOneExtractorPerETL(ctx.app, "fromOai");
        /**
         *  The cache keeps track of the last time it was updated. This value is
         *  called cache.lastUpdated.
         *
         *  Algorithm if caching is used:
         *
         *  - record the time. Call this currentRunStart.
         *  - read records from the API since cache.lastUpdated:
         *      if a record is marked as deleted:
         *        delete it from the cache
         *      else:
         *        save the record to the cache
         *        immediately process it
         *  - record the new cache.lastUpdated
         *  - read records from the cache, but ONLY those which haven't been
         *    modified since currentRunStart: apparently the others have already
         *    been processed while reading records from the API.
         */
        const selectors = opts?.selectors ? castArray(opts.selectors) : [];
        validatePaths(selectors);
        // loading the first page can take long, so already show a progress of 0%
        ctx.app.showProgress();
        /**
         * We may change the fromOai implementation, causing the cached results to be invalid
         * To force (after a Etl upgrade) to cache to be cleared, increment this number
         */
        const BUST_CACHE_ID = 1;
        const { since, set, metadataPrefix, cacheOverride, maxCacheAgeDays, ...options } = opts;
        if (options.verbosity === undefined)
            options.verbosity = ctx.app.verbosity;
        const oai = new Oai(options);
        const dirs = [options.url];
        if (metadataPrefix)
            dirs.push(metadataPrefix);
        if (set)
            dirs.push(set);
        const cacheDir = ctx.app.getCacheDir("source-oai", ...dirs);
        const cache = (await shouldUseCache(oai, cacheOverride, since)) ? await OaiCache.new(cacheDir) : undefined;
        if (since && cache) {
            // We don't want to throw an error because this is still useful for testing purposes.
            ctx.app.warn("Specifying 'since' in combination with using the cache is not supported and can corrupt the cache!");
        }
        let backgroundPromise = Promise.resolve();
        let cacheRecordCount = 0;
        let from;
        if (cache) {
            ctx.app.info("Using disk-based cache: " + cache.directory);
            const lastUpdated = await cache.readDate("lastUpdated");
            const cacheId = await cache.getCacheIndentifier();
            if (!lastUpdated) {
                ctx.app.info("This is a fresh cache!");
                // Clear the cache to make sure any stray records from failed previous
                // runs are removed.
                await cache.setCacheIdentifier(BUST_CACHE_ID);
                backgroundPromise = (await cache.clear()).promise;
                // adding cache override check for testing purposes
            }
            else if (cacheId !== BUST_CACHE_ID && opts.cacheOverride !== "use cache") {
                ctx.app.info("Clearing the cache due to Etl fromOai code changes");
                backgroundPromise = (await cache.clear()).promise;
                await cache.setCacheIdentifier(BUST_CACHE_ID);
            }
            else {
                const cacheCreated = await cache.readDate("cacheCreated");
                const cacheAgeMilliseconds = new Date().valueOf() - cacheCreated.valueOf();
                const cacheAgeDays = floor(cacheAgeMilliseconds / MILLISECONDS_IN_A_DAY);
                ctx.app.info(`The cache was created ${cacheAgeDays} days ago.`);
                const lastUpdatedMilliseconds = new Date().valueOf() - lastUpdated.valueOf();
                const lastUpdatedDays = floor(lastUpdatedMilliseconds / MILLISECONDS_IN_A_DAY);
                ctx.app.info(`The cache was last updated ${lastUpdatedDays} days ago.`);
                if (maxCacheAgeDays && cacheAgeDays > maxCacheAgeDays) {
                    ctx.app.info(`Clearing the cache because it is older than the allowed ${maxCacheAgeDays} days.`);
                    backgroundPromise = (await cache.clear()).promise;
                }
                else {
                    // Make sure that we don't fetch results that are already in the cache
                    cacheRecordCount = await cache.countRecords();
                    ctx.app.info(`The cache contains ${millify(cacheRecordCount, { precision: 1 })} records.`);
                    from = lastUpdated.toISOString().split(".")[0] + "Z";
                }
            }
        }
        // Because the only time we want to support `since` and caching is when
        // testing, and this is probably when testing the cache, we don't want to
        // overwrite the cache-calculated `from`.
        if (since && !from) {
            from = since.toISOString().split(".")[0] + "Z";
        }
        if (opts?.identifier) {
            const { identifier, metadataPrefix } = opts;
            const singleRecord = await oai.GetRecord({ identifier, metadataPrefix });
            if (singleRecord.header.status === "deleted") {
                await cache?.remove(singleRecord);
            }
            else {
                if (await cache?.add(singleRecord))
                    ctx.app.incrementProgress(1);
                singleRecord.header.fromCache = false;
                const enriched = {};
                if (!opts.skipEnrich) {
                    enriched.$recordId = ctx.recordId + 1;
                    enriched.$environment = Etl.environment;
                }
                await next({ ...enriched, ...(opts.skipTrim ? singleRecord : trimRecordFromSource(singleRecord)) }, ctx.app.getNewStore());
            }
            ctx.app.incrementProgress(1);
            return backgroundPromise;
        }
        const recordsIteratorOpts = {
            from,
            set,
            metadataPrefix: await oai.getMetadataPrefix(metadataPrefix),
            firstResponseCallback: async (totalAmmount) => {
                ctx.app.info(`Fetching a total of ${millify(totalAmmount, { precision: 1 })} records from the OAI API.`);
                ctx.app.setTotalProgress(totalAmmount + cacheRecordCount);
            },
        };
        if (options.verbosity > 2)
            recordsIteratorOpts.responseCallback = async (completeListSize, cursor, elapsed) => {
                ctx.app.info(`OAI-PMH update: cursor = ${millify(cursor, { precision: 1 })} for ${millify(completeListSize, {
                    precision: 1,
                })} records in ${msTohoursMinutSeconds(elapsed) ?? `${millify(elapsed, { precision: 1 })} ms`}.`);
            };
        const apiRecordsIterator = oai.recordsIterator(recordsIteratorOpts);
        const currentRunStart = new Date();
        let pendingNext = pReflect(apiRecordsIterator.next());
        while (true) {
            const iteratorResult = await pendingNext;
            if (iteratorResult.isRejected)
                throw iteratorResult.reason;
            if (iteratorResult.value.done)
                break;
            // Fetch next record, while we're process the results of the current record
            pendingNext = pReflect(apiRecordsIterator.next());
            for (const record of iteratorResult.value.value) {
                if (record.header.status === "deleted") {
                    await cache?.remove(record);
                }
                else {
                    // Increment the progress an additional time if the record already
                    // existed in the cache, because in that case it has been counted
                    // twice: once in the `cache.count()`, and once in the
                    // `resumptionInfo["@completeListSize"]`. We will, however, only
                    // process it once (now), and skip it when reading from the cache.
                    if (await cache?.add(record))
                        ctx.app.incrementProgress(1);
                    // Adding test data for trimming, hard to do without our own OAI-PMH server with data:
                    if (process.env.OAI_TESTER) {
                        _set(record.header, "OAI_TESTER", JSON.parse(process.env.OAI_TESTER));
                    }
                    /**
                     * Process records using selectors first, as each match on a selector will produce a new record
                     * As in one record may result various new records
                     */
                    if (selectors.length && cacheOverride !== "use cache") {
                        const matchedRecords = [];
                        for (const selector of selectors) {
                            const match = matchFromRecord(record, selector);
                            if (match)
                                matchedRecords.push(match);
                        }
                        for (const matchedRecord of matchedRecords) {
                            matchedRecord.fromCache = false;
                            const enriched = {};
                            if (!opts.skipEnrich) {
                                enriched.$recordId = ctx.recordId + 1;
                                enriched.$environment = Etl.environment;
                            }
                            await next({ ...enriched, ...(opts.skipTrim ? matchedRecord : trimRecordFromSource(matchedRecord)) }, ctx.app.getNewStore());
                        }
                    }
                    else {
                        record.header.fromCache = false;
                        const enriched = {};
                        if (!opts.skipEnrich) {
                            enriched.$recordId = ctx.recordId + 1;
                            enriched.$environment = Etl.environment;
                        }
                        const returnRecord = opts.verb === "ListIdentifiers" ? record.header : record;
                        await next({ ...enriched, ...(opts.skipTrim ? returnRecord : trimRecordFromSource(returnRecord)) }, ctx.app.getNewStore());
                    }
                }
                // going to be hard to update the status correctly as we don't know how many matches to expect.
                ctx.app.incrementProgress(1);
            }
        }
        if (cache) {
            await cache.writeDate("lastUpdated");
            let recordsReturned = 0;
            for await (const record of cache.iterate(currentRunStart)) {
                if (selectors.length) {
                    const matchedRecords = [];
                    for (const selector of selectors) {
                        const match = matchFromRecord(record, selector);
                        if (match)
                            matchedRecords.push(match);
                    }
                    for (const matchedRecord of matchedRecords) {
                        matchedRecord.fromCache = true;
                        recordsReturned++;
                        const enriched = {};
                        if (!opts.skipEnrich) {
                            enriched.$recordId = ctx.recordId + 1;
                            enriched.$environment = Etl.environment;
                        }
                        await next({ ...enriched, ...(opts.skipTrim ? matchedRecord : trimRecordFromSource(matchedRecord)) }, ctx.app.getNewStore());
                    }
                }
                else {
                    recordsReturned++;
                    record.header.fromCache = true;
                    await next(record, ctx.app.getNewStore());
                }
                ctx.app.incrementProgress(1);
            }
            ctx.app.info(`Returned ${recordsReturned} record${recordsReturned === 1 ? "" : "s"} from the cache.`);
        }
        // Repeating this message at the end because someone may have missed it
        // because of lots of shaclValidate output
        if (since && cache) {
            ctx.app.warn("I repeat: specifying 'since' in combination with using the cache is not supported and can corrupt the cache!");
        }
        return backgroundPromise;
    }, { sourceFuncName: "_fromOai" });
}
async function shouldUseCache(oai, userOverride, since) {
    return (userOverride === "use cache" || (!since && !userOverride && (await oai.identify()).deletedRecord === "persistent"));
}
export class Oai {
    constructor(opts) {
        const { url, verbosity, timeout, verb } = opts;
        this.url = url;
        this.verb = verb;
        this.verbosity = verbosity ?? 0;
        this.timeout = (timeout ?? 1) * 60 * 1000;
    }
    async fetch(verb, options) {
        const url = this.url + "?" + new URLSearchParams({ verb: verb, ...options });
        if (this.verbosity > 1)
            console.info("fetching", url);
        const response = await pTimeout(fetch(url), {
            milliseconds: this.timeout,
            message: `Request to ${url} timed out (timeout is set to ${this.timeout} ms)`,
        });
        if (!response.ok)
            throw new Error(`[${response.status}: ${response.statusText}] Failed to fetch ${url}: ${await response.text()}` +
                (response.status === 500 ? " You may want to specify the argument `set` in the options to fromOai" : ""));
        const contentTypeHeader = response.headers.get("Content-Type") ?? "text/xml";
        const contentType = contentTypeHeader.split(";")[0].trim().toLowerCase();
        let responseJson;
        if (contentType === "application/json") {
            responseJson = await response.json();
        }
        else {
            const parserOptions = {
                attributeNamePrefix: "@",
                ignoreAttributes: false,
                // Do not post-process attribute values, e.g. trimming them, casting to boolean, or trying to magically cast to number
                // See https://issues.triply.cc/issues/6940
                parseAttributeValue: false,
                parseTagValue: false,
                textNodeName: "$text",
                alwaysCreateTextNode: true,
                isArray: (_1, jPath, _2, isAttribute) => !isAttribute && jPath.startsWith("OAI-PMH.ListRecords.record.metadata.record."),
            };
            const xmlParser = new XMLParser(parserOptions);
            const body = await response.text();
            if (this.verbosity > 2)
                console.info("response:", body);
            responseJson = await xmlParser.parse(body);
        }
        assertIsObject(responseJson, `Expected an object as OAI response to ${url}. Response JSON: ` + JSON.stringify(responseJson));
        assertIn("OAI-PMH", responseJson, url);
        responseJson = responseJson["OAI-PMH"];
        if ("error" in responseJson) {
            const error = responseJson.error;
            let extraText = "";
            if (verb === "ListRecords" && error["@code"] === "badArgument" && error["$text"].includes("Set")) {
                extraText = ` Available sets: ${(await this.listSets()).map((s) => s.setSpec).join(", ")}.`;
            }
            throw new OaiError({ error, url, extraText });
        }
        assertIn(verb, responseJson, url);
        return responseJson[verb];
    }
    async identify() {
        return stringifyTextNodes(await this.fetch("Identify", {}));
    }
    async listMetadataFormats() {
        const response = await this.fetch("ListMetadataFormats", {});
        assertIn("metadataFormat", response);
        return castArray(response["metadataFormat"]).map(stringifyTextNodes);
    }
    async GetRecord(opts) {
        const { identifier, metadataPrefix } = opts;
        const ensureMetadataPrefix = metadataPrefix || "oai_dc";
        const response = await this.fetch("GetRecord", { identifier, metadataPrefix: ensureMetadataPrefix });
        assertIn("record", response);
        response.record.header = stringifyTextNodes(response.record.header);
        return response.record;
    }
    async listRecordsPage(opts) {
        if (this.verb === "ListIdentifiers")
            return this.listIdentifierPage(opts);
        if ("from" in opts && !opts.from)
            delete opts.from;
        if ("set" in opts && !opts.set)
            delete opts.set;
        const response = await this.fetch("ListRecords", opts);
        assertIn("record", response);
        response.record = castArray(response.record).map((record) => {
            if (!record)
                throw new Error("One of the records is not defined. This means the OAI api doesn't follow the spec. Please report this to owner of the OAI-PMH Api.");
            record.header = stringifyTextNodes(record.header);
            return record;
        });
        if ("resumptionToken" in response)
            response.resumptionToken = parseResumptionInfo(response.resumptionToken);
        return response;
    }
    async listIdentifierPage(opts) {
        if ("from" in opts && !opts.from)
            delete opts.from;
        if ("set" in opts && !opts.set)
            delete opts.set;
        const response = await this.fetch("ListIdentifiers", opts);
        assertIn("header", response);
        response.record = castArray(response.header).map((record) => {
            if (!record)
                throw new Error("One of the records is not defined. This means the OAI api doesn't follow the spec. Please report this to owner of the OAI-PMH Api.");
            return { header: stringifyTextNodes(record) };
        });
        if ("resumptionToken" in response)
            response.resumptionToken = parseResumptionInfo(response.resumptionToken);
        return response;
    }
    async listSetsPage(opts) {
        const response = await this.fetch("ListSets", opts);
        assertIn("set", response);
        response.set = castArray(response.set).map(stringifyTextNodes);
        if ("resumptionToken" in response)
            response.resumptionToken = parseResumptionInfo(response.resumptionToken);
        return response;
    }
    async getMetadataPrefix(metadataPrefix) {
        const supportedPrefixes = (await this.listMetadataFormats()).map((f) => f.metadataPrefix);
        if (supportedPrefixes.length === 0)
            throw new Error("OAI lists no metadata formats.");
        if (metadataPrefix) {
            if (!supportedPrefixes.includes(metadataPrefix))
                throw new Error(`'${metadataPrefix}' is not listed as a supported metadataPrefix. Choose from: ${supportedPrefixes}`);
        }
        else {
            if (supportedPrefixes.length !== 1)
                throw new Error("Please specify a metadataPrefix. Choose from: " + supportedPrefixes);
            metadataPrefix = supportedPrefixes[0];
        }
        return metadataPrefix;
    }
    async listSets() {
        const sets = [];
        for await (const set of this.setsIterator()) {
            sets.push(set);
        }
        return sets;
    }
    setsIterator() {
        return new OaiSetsIterator(this);
    }
    recordsIterator(opts) {
        return new OaiRecordsIterator(this, opts);
    }
}
class OaiRecordsIterator {
    constructor(oai, opts) {
        this.firstResponseCallback = async () => { };
        this.responseCallback = async () => { };
        this.oai = oai;
        const { firstResponseCallback, responseCallback, ...listRecordsOptions } = opts;
        this.firstResponseCallback = firstResponseCallback ?? (async () => { });
        this.responseCallback = responseCallback ?? (async () => { });
        this.started = false;
        this.listRecordsOptions = listRecordsOptions;
    }
    async next() {
        let options;
        if (!this.started) {
            this.started = true;
            options = this.listRecordsOptions;
        }
        else if (this.resumptionToken) {
            options = { resumptionToken: this.resumptionToken };
        }
        else {
            return { done: true, value: undefined };
        }
        let result;
        try {
            const time = new Date().getTime();
            result = await this.oai.listRecordsPage(options);
            if ("resumptionToken" in options) {
                const completeListSize = result.resumptionToken?.["@completeListSize"] ?? -1;
                const cursor = result.resumptionToken?.["@cursor"] ?? -1;
                await this.responseCallback(completeListSize, cursor, new Date().getTime() - time);
            }
        }
        catch (e) {
            if (e instanceof OaiError && e.error["@code"] === "noRecordsMatch" && !("resumptionToken" in options)) {
                // This is the first call to the API, and apparently there's just an
                // empty list.
                await this.firstResponseCallback(0);
                return { done: true, value: undefined };
            }
            throw e;
        }
        this.resumptionToken = result.resumptionToken?.["$text"];
        if (!("resumptionToken" in options)) {
            await this.firstResponseCallback(result.resumptionToken?.["@completeListSize"] ?? result.record.length);
        }
        return {
            value: result.record,
            done: false,
        };
    }
    [Symbol.asyncIterator]() {
        return this;
    }
}
class OaiSetsIterator {
    constructor(oai) {
        /** last element of the array is next up */
        this.buffer = [];
        this.oai = oai;
        this.started = false;
    }
    async next() {
        if (this.buffer.length === 0) {
            let options;
            if (!this.started) {
                this.started = true;
                options = {};
            }
            else if (this.resumptionToken) {
                options = { resumptionToken: this.resumptionToken };
            }
            else {
                return { done: true, value: undefined };
            }
            const result = await this.oai.listSetsPage(options);
            this.buffer = result.set.reverse(); // pop from the back
            this.resumptionToken = result.resumptionToken?.["$text"];
        }
        return {
            value: this.buffer.pop(),
            done: false,
        };
    }
    [Symbol.asyncIterator]() {
        return this;
    }
}
export class OaiCache {
    constructor(directory) {
        this.prefixSize = 2;
        this.directory = directory;
    }
    static async new(cacheDir) {
        const cache = new OaiCache(cacheDir);
        await fs.ensureDir(cacheDir);
        await cache.writeDate("cacheCreated");
        return cache;
    }
    getCacheIdPath() {
        return resolve(this.directory, ".cacheId");
    }
    async getCacheIndentifier() {
        const cacheIdPath = await this.getCacheIdPath();
        if (!(await fs.pathExists(cacheIdPath)))
            return 0;
        return +(await fs.readFile(cacheIdPath, "utf-8"));
    }
    async setCacheIdentifier(cacheId) {
        const cacheIdPath = this.getCacheIdPath();
        return fs.writeFile(cacheIdPath, "" + cacheId);
    }
    async readDate(name) {
        const filename = resolve(this.directory, name + ".isodate.txt");
        let date;
        if (await fs.pathExists(filename))
            date = new Date(await fs.readFile(filename, "utf-8"));
        if (name === "cacheCreated" && !date)
            throw new Error("cacheCreated wasn't defined. Please report this to a developer if you haven't been messing with the cache yourself.");
        return date;
    }
    /** Write a date (with day-precision) to the cache metadata. */
    async writeDate(name) {
        const path = resolve(this.directory, name + ".isodate.txt");
        if (name === "cacheCreated" && (await fs.pathExists(path)))
            return;
        // We don't have to save yesterdays date for `lastUpdated`, because we
        // send the API a minute-precise ISO datetime which specifies the _start_
        // of the lastUpdated day.
        const dateString = new Date().toISOString().split("T")[0];
        return fs.writeFile(path, dateString, "utf-8");
    }
    /**
     *  Clear the cache.
     *  The inner promise can safely be executed while writing new entries.
     */
    async clear() {
        const removePath = this.directory + "-to-be-removed-" + Math.random();
        await fs.move(this.directory, removePath);
        await fs.mkdir(this.directory);
        await this.writeDate("cacheCreated");
        return {
            promise: fs.remove(removePath),
        };
    }
    /** Get a filesystem-safe unique ID for a record */
    static id(record) {
        return md5OfArray([record.header.identifier]);
    }
    filesystemInfo(record) {
        const id = OaiCache.id(record);
        const dir = resolve(this.directory, id.slice(0, this.prefixSize));
        const fullPath = resolve(dir, id.slice(this.prefixSize) + ".json");
        return { dir, fullPath };
    }
    /**
     *  Iterate over all the cached records, in arbitrary order.
     *
     *  @param cutOffTimeForFilesToInclude
     *           If the last modified date of the file on disc is after
     *           `cutOffTimeForFilesToInclude` the record will be excluded.
     */
    async *iterate(cutOffTimeForFilesToInclude) {
        for (const directory of await fs.readdir(this.directory)) {
            const dirpath = resolve(this.directory, directory);
            if (!(await fs.stat(dirpath)).isDirectory())
                continue;
            for (const filename of await fs.readdir(dirpath)) {
                const path = resolve(this.directory, directory, filename);
                // Was breaking trying to read set cache directories
                if ((await fs.stat(path)).isDirectory())
                    continue;
                if (cutOffTimeForFilesToInclude && (await fs.stat(path)).mtime > cutOffTimeForFilesToInclude)
                    continue;
                // Avoids reading files that aren't json
                if (!path.endsWith("json"))
                    continue;
                yield (await fs.readJson(path));
            }
        }
    }
    /**
     *  Write a record to cache. Overwrites existing entry with the same ID.
     *
     *  @returns Whether the entry already existed in the cache.
     */
    async add(record) {
        const { dir, fullPath } = this.filesystemInfo(record);
        await fs.ensureDir(dir);
        const alreadyThere = await fs.pathExists(fullPath);
        await fs.writeJson(fullPath, record);
        return alreadyThere;
    }
    /**
     *  Remove a record from the cache.
     */
    async remove(record) {
        const { fullPath } = this.filesystemInfo(record);
        return fs.remove(fullPath);
    }
    /**
     *  Count the number of entries in the cache.
     */
    async countRecords() {
        return sum(await Promise.all((await fs.readdir(this.directory)).map(async (subdir) => {
            const path = resolve(this.directory, subdir);
            if ((await fs.stat(path)).isDirectory())
                return (await fs.readdir(path)).length;
            else
                return 0;
        })));
    }
}
function parseResumptionInfo(info) {
    assertIn("@completeListSize", info);
    assertIn("@cursor", info);
    return {
        "@completeListSize": new Number(info["@completeListSize"]).valueOf(),
        "@cursor": new Number(info["@cursor"]).valueOf(),
        $text: info["$text"],
    };
}
function assertIn(key, json, url) {
    if (!(key in json)) {
        throw new Error(`Expected '${key}' to be in the OAI response${url ? " of " + url : ""}. This is most likely because the OAI-PMH server is unresponsive. You should contact the owner of the service. Response JSON: ` +
            JSON.stringify(json));
    }
}
/**
 *  Recursively convert any node that looks like `{ '$text': string }` to a simple `string`
 */
function stringifyTextNodes(object) {
    if (typeof object === "object") {
        const keys = Object.keys(object);
        if (keys.length === 1 && keys[0] === "$text") {
            return object["$text"];
        }
        else {
            return mapValues(object, (sub) => stringifyTextNodes(sub));
        }
    }
    return object;
}
//# sourceMappingURL=fromOai.js.map