import chai, { expect } from "chai";
import chaiAsPromised from "chai-as-promised";
import * as fs from "fs";
import fse from "fs-extra";
import { Etl, fromJson, Source } from "../../generic/index.js";
import { randomUUID } from "crypto";
import path from "path";
import logRecord from "../logRecord.js";
chai.use(chaiAsPromised);
// make UUID tmp directory
const tmpDataDir = path.resolve("data", "tmp", "unit-tests", randomUUID());
const destination = path.resolve(tmpDataDir, `${randomUUID()}.json`);
const nestedDestination = path.resolve(tmpDataDir, "nestedFolder", `${randomUUID()}.json`);
describe("logRecord destination", () => {
    after(async function () {
        await fse.emptyDir(tmpDataDir);
    });
    it("Should write record to new file in specified destination, containing expected JSON content and readable in ETL", async () => {
        const etl = new Etl();
        etl.use(fromJson([{ foo: "bar1" }, { foo: "bar2" }]), logRecord({ destination }));
        await etl.run();
        // For testing
        const finalRecord = { foo: "bar2", $recordId: 2, $environment: "Development" };
        const writtenFile = JSON.parse(fs.readFileSync(destination, "utf-8"));
        expect(fs.existsSync(destination)).to.be.true;
        expect(writtenFile).to.deep.equal(finalRecord);
        // Reading created file in ETL
        const newETL = new Etl();
        newETL.use(fromJson(Source.file(destination), { skipEnrich: true }), (ctx, next) => {
            expect(ctx.record).to.deep.equal(finalRecord);
            return next();
        });
        await newETL.run();
    });
    it("Should make new folder and write record to file in specified destination, containing expected JSON content and readable in ETL", async () => {
        const etl = new Etl();
        etl.use(fromJson([{ foo: "bar1" }, { foo: "bar2" }]), logRecord({ destination: nestedDestination }));
        await etl.run();
        // For testing
        const finalRecord = { foo: "bar2", $recordId: 2, $environment: "Development" };
        const writtenFile = JSON.parse(fs.readFileSync(nestedDestination, "utf-8"));
        expect(fs.existsSync(nestedDestination)).to.be.true;
        expect(writtenFile).to.deep.equal(finalRecord);
        // Reading created file in ETL
        const newETL = new Etl();
        newETL.use(fromJson(Source.file(nestedDestination), { skipEnrich: true }), (ctx, next) => {
            expect(ctx.record).to.deep.equal(finalRecord);
            return next();
        });
        await newETL.run();
    });
    it("Should write to existing folder", async () => {
        const etl = new Etl();
        fs.mkdirSync(path.resolve(tmpDataDir, "folder"));
        etl.use(logRecord({ destination: path.resolve(tmpDataDir, "folder", "toExistingFolder.json") }));
        await expect(etl.run()).to.be.eventually.fulfilled;
    });
    it("Should fail for illegal file write operations", async () => {
        const etl = new Etl();
        fs.mkdirSync(path.resolve(tmpDataDir, "folder.json"));
        etl.use(logRecord({ destination: path.resolve(tmpDataDir, "folder.json") }));
        await expect(etl.run()).to.be.rejectedWith("EISDIR: illegal operation on a directory");
    });
    it("Should fail for just destination 'file.txt' argument", async () => {
        const etl = new Etl();
        const destinationWrongExtension = path.resolve("file.txt");
        etl.use(logRecord({ destination: destinationWrongExtension }));
        await expect(etl.run()).to.be.rejectedWith('Please provide a valid file name for destination with JSON extension (e.g. "logRecord.json", "./data/logRecord.json")');
    });
    it("Should fail for just '.json' argument", async () => {
        const etl = new Etl();
        const destinationWrongArg = path.resolve(".json");
        etl.use(logRecord({ destination: destinationWrongArg }));
        await expect(etl.run()).to.be.rejectedWith('Please provide a valid file name for destination with JSON extension (e.g. "logRecord.json", "./data/logRecord.json")');
    });
});
//# sourceMappingURL=logRecord.test.js.map