import TriplyDb, { AppConfig as TriplyDbConfig } from "@triply/triplydb/App.js";
import { Destination } from "./index.js";
import Multistream from "multistream";
import fs from "fs-extra";
import { getTriplyDb } from "../index.js";
import * as zlib from "zlib";
import Dataset from "@triply/triplydb/Dataset.js";
import { IncompatibleError, TriplyDbJsError } from "@triply/triplydb/utils/Error.js";
import { UpdateDataset as UpdateDatasetCore, NewDataset } from "@triply/utils/Models.js";
import pumpify from "pumpify";
import Graph from "@triply/triplydb/Graph.js";
import path from "path";
import { coerceToIri, NamedNodeCompatibleType } from "../../../utils/index.js";
import { FileSourceInfo } from "../sources/index.js";
import { Store, getFactory, getStreamParser } from "@triplydb/data-factory";
import crypto from "crypto";
import { castArray } from "lodash-es";
import { ServiceMetadata } from "@triply/utils/Models.js";
import { sh } from "@triplyetl/vocabularies";
import { Quad as N3Quad } from "n3";
type DatasetInfo = Awaited<ReturnType<Dataset["getInfo"]>>;
type ApiConfig = Awaited<ReturnType<TriplyDb["getInfo"]>>;
function getDatasetUrl(apiConfig: ApiConfig, datasetInfo: DatasetInfo) {
  return `${apiConfig.consoleUrl}/${datasetInfo.owner.accountName}/${datasetInfo.name}`;
}
export interface AllOptions {
  /**
   * Remove all pre-existing graphs from the dataset  (default: false)
   */
  truncateGraphs: boolean;

  /**
   * Overwrite graphs. By default, it will rename graphs if they already exist
   * Currently, this is only supported when using named graphs. Overwriting default graphs is not supported.
   */
  overwrite: boolean;

  mergeGraphs: boolean;
  /**
   * After a successful upload, automatically synchronizes out-of-date services for the dataset. If a service
   * is being stopped or removed, then it will be skipped from synchronization. If a service has raised an
   * error, then the synchronization will fail.  (default: false)
   */
  synchronizeServices: boolean | string | string[];
  triplyDb?: TriplyDb | TriplyDbConfig;
  /**
   * Default graph. By default, the default graph from the Etl app is used
   */
  defaultGraph?: NamedNodeCompatibleType;

  /**
   * Register this dataset with the [NDE Dataset register](https://datasetregister.netwerkdigitaalerfgoed.nl/)
   */
  submitToNDEDatasetRegister?: boolean;

  /**
   * When using metadata to change existing Datasets, this value specifies if that metadata should be merged, replaced or kept.
   * To prevend overwriting metadata provided in the UI/website, the default value is 'keep'. When 'merge' is used, only empty values will be replaced.
   * For new datasets this value is ignored and the metadata is always used.
   */
  existingMetadata?: "merge" | "replace" | "keep";
}

interface DefaultOptions extends AllOptions {
  overwrite: true;
  mergeGraphs: false;
}

interface MergeOptions extends AllOptions {
  overwrite: false;
  truncateGraphs: false;
  mergeGraphs: true;
}

export type DatasetMetadata = Partial<Omit<UpdateDatasetCore, "topics">> & { name: string };

const isUpdateDataSet = (val: any): val is DatasetMetadata => typeof val === "object" && Object.hasOwn(val, "name");

export type Options = MergeOptions | DefaultOptions;

export default function rdf(datasetName: string | Partial<DatasetMetadata>, options?: Partial<Options>): Destination;
export default function rdf(
  accountName: string,
  datasetName: string | Partial<DatasetMetadata>,
  options?: Partial<Options>,
): Destination;
export default function rdf(
  accountNameOrDatasetName: string | Partial<DatasetMetadata>,
  optionsOrDatasetName: string | Partial<Options> | Partial<DatasetMetadata> | undefined,
  optionalOptions?: Partial<Options>,
): Destination {
  // !!NB!!   Apart from the arguments passed to the destination, this scope
  //          must not contain any state. For example, the state must not
  //          depend on `app`, because a destination may be re-used across
  //          apps.
  let accountName: string | undefined;
  let datasetMetadata: DatasetMetadata;
  let datasetnameIsObject: boolean = false;

  let options: AllOptions = {
    overwrite: true,
    truncateGraphs: false,
    synchronizeServices: true,
    mergeGraphs: false,
    existingMetadata: "keep",
  };

  if (typeof accountNameOrDatasetName === "string" && typeof optionsOrDatasetName === "string") {
    if (accountNameOrDatasetName !== "me") {
      accountName = accountNameOrDatasetName;
    }
    datasetMetadata = { name: optionsOrDatasetName };
    options = { ...options, ...optionalOptions };
  } else if (typeof accountNameOrDatasetName === "string" && isUpdateDataSet(optionsOrDatasetName)) {
    if (accountNameOrDatasetName !== "me") {
      accountName = accountNameOrDatasetName;
    }
    datasetMetadata = optionsOrDatasetName;
    options = { ...options, ...optionalOptions };
    datasetnameIsObject = true;
  } else if (isUpdateDataSet(accountNameOrDatasetName)) {
    datasetMetadata = accountNameOrDatasetName;
    if (typeof optionsOrDatasetName === "object") {
      options = { ...options, ...optionsOrDatasetName };
    }
    datasetnameIsObject = true;
  } else {
    datasetMetadata = { name: accountNameOrDatasetName as string };
    if (typeof optionsOrDatasetName === "object") {
      options = { ...options, ...optionsOrDatasetName };
    }
  }

  // if the user asks to merge graphs, we should not use truncateGraphs and/or overwrite flags:
  if (options.mergeGraphs === true) {
    options.overwrite = false;
    options.truncateGraphs = false;
  }
  const url = (
    options.triplyDb === undefined || options.triplyDb instanceof TriplyDb
      ? options.triplyDb
      : TriplyDb.get(options.triplyDb)
  )?.getConfig()?.url;
  // creating a MD5 hash of the options to use as unique fingerprint identifier
  const jsonOptionsString = JSON.stringify(options);
  const hashedOptionsString = crypto.createHash("md5").update(jsonOptionsString).digest("hex");
  return {
    type: "rdf",
    // Fingerprint
    // -----------
    // api url:
    //    If the user specified an api in the options (either by url or token
    //    or whatever), `url` will contain it. Otherwise, the default
    //    app.triplyDb will be used, which is always the same for the same
    //    app.
    // account name:
    //    account names cannot contain `<` or `>`, so the account name will
    //    never collide with `<undefined>`. `undefined` means that we use
    //    whatever was specified on the command-line or in the token, but in
    //    any case `undefined` will always resolve to the same account within
    //    the same app.
    //
    // the dataset name in combination with a hash created from the proviced options will uniquely identify the key of the file info
    fingerprint: `rdf://${url}/${accountName ?? "<undefined>"}/${datasetMetadata.name}/${hashedOptionsString}`,
    fileInfo: { extension: "trig", compression: undefined },
    registerSource,
    init: async (app) => {
      const tdb = getTriplyDb(app, options.triplyDb);
      const account = await tdb.getAccount(accountName ?? app["_defaultAccount"]);
      const metadata: Omit<NewDataset, "name"> = {};
      if (datasetMetadata.accessLevel) metadata.accessLevel = datasetMetadata.accessLevel;
      if (datasetMetadata.displayName) metadata.displayName = datasetMetadata.displayName;
      if (datasetMetadata.description) metadata.description = datasetMetadata.description;
      if (datasetMetadata.license) metadata.license = datasetMetadata.license;

      try {
        // Do an info call, to make sure we have access to this dataset.
        // We don't want such feedback only after the ETL ran
        const ds = await account.getDataset(datasetMetadata.name);
        if (datasetnameIsObject) {
          if (options.existingMetadata !== "keep") {
            let metadataUpdate: UpdateDatasetCore = {};
            if (options.existingMetadata === "merge") {
              const info = await ds.getInfo();
              if ((info.displayName ?? "") === "") metadataUpdate.displayName = metadata.displayName;
              if ((info.description ?? "") === "") metadataUpdate.description = metadata.description;
              if (info.license === undefined) metadataUpdate.license = metadata.license;
              if (
                (info.exampleResources ?? []).length === 0 &&
                datasetMetadata.exampleResources !== undefined &&
                datasetMetadata.exampleResources.length > 0
              )
                metadataUpdate.exampleResources = datasetMetadata.exampleResources;
            } else {
              metadataUpdate = metadata;
              if (datasetMetadata.exampleResources) {
                metadataUpdate.exampleResources = datasetMetadata.exampleResources;
              }
            }
            if (Object.keys(metadata).length > 0) await ds.update(metadataUpdate);
          } else {
            if (Object.values(metadata).filter((val) => val !== undefined).length > 0) {
              app.warn("ignoring the dataset's metadata for existing datasets");
            }
          }
        }
      } catch (e) {
        if (e instanceof TriplyDbJsError && e.statusCode === 404) {
          if (datasetMetadata.exampleResources) {
            app.warn("You can not add example resources on new datasets.");
          }
          const dataset = await account.addDataset(datasetMetadata.name, metadata);
          app.info(`Created new dataset at ${getDatasetUrl(await tdb.getInfo(), await dataset.getInfo())}`);
        } else {
          throw e;
        }
      }
    },
    postProcess: async (app, filesWithMetaData) => {
      const files = filesWithMetaData.map((f) => f.filename);
      const filesToRemove = filesWithMetaData.filter((f) => f.remove).map((f) => f.filename);

      const tdb = getTriplyDb(app, options.triplyDb);
      const account = await tdb.getAccount(accountName ?? app["_defaultAccount"]);
      const datasetObject = await account.getDataset(datasetMetadata.name);

      const info = await tdb.getInfo();
      const datasetUrl = getDatasetUrl(info, await datasetObject.getInfo());
      app.info(`Started uploading graphs to ${datasetUrl}`);
      if (tdb.getConfig().url !== info.apiUrl) app.info(`  - using API URL: ${tdb.getConfig().url}`);

      if (options.truncateGraphs) {
        await datasetObject.clear("graphs");
      }
      try {
        /**
         * Given the files + ETL app, we upload the files with the given defaultGraph name
         * @remarks importFromFiles behavior: this defaultGraph name from destination is unused when a ".trig" file is provided with a named graph, instead the graph name in the ".trig" file is used during upload
         */
        await datasetObject.importFromFiles(files, {
          overwriteAll: options.overwrite,
          mergeGraphs: options.mergeGraphs,
          defaultGraphName: options.defaultGraph ? coerceToIri(options.defaultGraph).value : app.defaultGraph.value,
        });
      } catch (e) {
        if (!(e instanceof IncompatibleError)) {
          throw e;
        }
        /**
         * Assuming we got an incompatibility error because the TriplyDB api does not support the overwrite flag.
         * So, using the workaround below
         */
        const graphsInDataset = await datasetObject.getGraphs().toArray();
        if (graphsInDataset.length) {
          /**
           * This is suboptimal. Keeping this functionality for supporting overwriting graphs on APIs with an old version.
           * Details at https://issues.triply.cc/issues/4923
           */
          const graphNamesInDataset: { [graphName: string]: Graph } = {};
          for (const graph of graphsInDataset) {
            graphNamesInDataset[(await graph.getInfo()).graphName] = graph;
          }

          // Remove 'any' trick after @types/multistream is upgraded. Right now, we cant use it as a constructor
          let _Multistream: any = Multistream;
          const statements = new pumpify.obj([
            new _Multistream(
              files.map((f) => {
                const stream = fs.createReadStream(f);
                if (f.endsWith(".gz")) {
                  return new pumpify([stream, zlib.createGunzip()]);
                } else {
                  return stream;
                }
              }),
            ),
            getStreamParser(),
          ]);

          const graphs = new Set<string>();
          for await (const statement of statements) {
            if (statement.graph && statement.graph.value) {
              graphs.add(statement.graph.value);
            }
          }
          for (const graphName of graphs) {
            if (graphNamesInDataset[graphName]) {
              await graphNamesInDataset[graphName].delete();
            }
          }
        }
        await datasetObject.importFromFiles(files);
      }
      app.info(`Successfully uploaded graphs to ${datasetUrl}`);

      // uploadPrefixes({dataset: datasetName, account: accountName})(ctx, () => )
      const prefixes = { ...app.prefix, ...app.standardPrefixes };
      await datasetObject.addPrefixes(prefixes);
      // see https://git.triply.cc/triply/etl/-/issues/276 and https://git.triply.cc/triply/etl/-/issues/210
      // app.info(
      //   `Successfully uploaded ${Object.keys(prefixes).length} prefix${
      //     Object.keys(prefixes).length > 1 ? "es" : ""
      //   } to ${datasetUrl}`,
      // );

      // We've uploaded them successfully, let's remove the files
      await Promise.all(filesToRemove.map((f) => fs.remove(f)));

      // Check for out-of-date services
      const stats = {
        total: 0,
        outdated: 0,
        updated: 0,
        skipped: 0,
      };
      const synchronizeServices: boolean =
        typeof options.synchronizeServices === "boolean"
          ? options.synchronizeServices
          : Array.isArray(options.synchronizeServices) && options.synchronizeServices.length !== 0
          ? true
          : options.synchronizeServices !== undefined;
      let filter = (_: ServiceMetadata) => true;
      if (options.synchronizeServices !== undefined && typeof options.synchronizeServices !== "boolean") {
        const serviceNames = castArray(options.synchronizeServices);
        filter = (info: ServiceMetadata) => {
          const hasName = serviceNames.includes(info.name);
          if (!hasName) {
            app.warn(`Service ${info.name} in dataset ${datasetUrl} not selected to be synchronized.`);
            stats.skipped++;
          }
          return hasName;
        };
      }
      const services = await datasetObject.getServices().toArray();
      stats.total = services.length;
      await Promise.all(
        services.map(async (service) => {
          const info = await service.getInfo();
          if (synchronizeServices && filter(info)) {
            if (["removing", "stopping", "stopped"].includes(info.status)) {
              app.info(
                `Service ${info.name} in dataset ${datasetUrl} will not be synchronized as it has the status '${info.status}'.`,
              );
              stats.skipped++;
              return;
            }
            if (info.status === "error") {
              throw new Error(
                `Service ${info.name} in dataset ${datasetUrl} cannot be synchronized as it has an error.`,
              );
            }
            // Ensure that the service is running.
            if (["starting", "updating"].includes(info.status)) {
              app.warn(`Waiting on service ${info.name} in ${datasetUrl} to be running.`);
              await service.waitUntilRunning();
              app.warn(`Service ${info.name} in ${datasetUrl} is running.`);
              stats.updated++;
            }
            // Wait for the service to be synchronized.
            if (!(await service.isUpToDate())) {
              stats.outdated++;
              await service.update();
              stats.updated++;
            }
          } else {
            // Count the number of out-of-date services, to notify the user.
            if (!(await service.isUpToDate())) stats.outdated++;
          }
        }),
      );

      // Inform the user if services were synchronized, or could have been synchronized.
      if (services.length > 0) {
        if (options.synchronizeServices) {
          if (stats.total === stats.updated) {
            app.info(
              `Synchronized ${stats.total === 1 ? "the service" : `all ${stats.total} services`} in ${datasetUrl}`,
            );
          } else {
            app.info(`Synchronized ${stats.updated} of ${stats.total} services in ${datasetUrl}`);
          }
        }
      }

      // register the dataset against the NDE Dataset Register:
      if (options.submitToNDEDatasetRegister ?? false) {
        try {
          await datasetObject.nde.datasetregister.submit();
          app.info("The dataset is submitted to the NDE Dataset Register");
        } catch (e) {
          const err = e as Error & { report: N3Quad[] };
          const lines = (e as Error).message.split("\n");
          app.error(lines.shift() ?? "Unkown error => this should not happen please consult Triply DIT.");
          const factory = getFactory();
          new Store(err.report.map((q) => factory.fromQuad(q)))
            .getObjects(null, sh.resultMessage, null)
            .filter((msg) => msg.termType === "Literal" && msg.language === "en")
            .map((msg) => app.error(msg.value));
          lines.forEach((line) => app.info(line));
        }
      }
    },
  };
}

// used in copySource in Etl.ts to register the source file
async function registerSource(source: FileSourceInfo, tmpDir: string) {
  const file = path.resolve(await source.getLocalPath());
  let postFix = "";
  const extension = await source.extension();
  if (extension) {
    postFix += "." + extension;
  }
  const compression = await source.compression();
  if (compression) {
    postFix += "." + compression;
  }
  if (file.endsWith(postFix)) {
    // we can use this file, but we shouldn't remove it when we're done
    return { filename: file, remove: false };
  } else {
    // We really have to copy the file to give it a new name #5142
    // Remove full-stops because of #5103
    const tmpFile = path.resolve(tmpDir, path.basename(file.replace(/\./g, "")) + Math.random() + postFix);
    await fs.copy(file, tmpFile);
    return { filename: tmpFile, remove: true };
  }
}
