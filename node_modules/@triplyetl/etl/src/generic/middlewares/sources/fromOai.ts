import { Etl, Middleware } from "../../index.js";
import { addMwCallSiteToError, assertOneExtractorPerETL, md5OfArray } from "../../../utils/index.js";
import { X2jOptionsOptional as XmlParserOptions, XMLParser } from "fast-xml-parser";
import { assertIsObject } from "../../../utils/asserts.js";
import { castArray, floor, mapValues, sum, set as _set } from "lodash-es";
import fs from "fs-extra";
import { resolve } from "path";
import { millify } from "millify";
import pTimeout from "p-timeout";
import fetch from "cross-fetch";
import pReflect from "p-reflect";
const MILLISECONDS_IN_A_DAY = 1000 * 60 * 60 * 24;
import { Record } from "../../Record.js";
import trimRecordFromSource from "./util/trimRecordFromSource.js";
import msTohoursMinutSeconds from "../../../utils/msTohms.js";
import { validatePaths } from "./fromXml.js";
import { matchFromRecord } from "./fromJson.js";

class OaiError extends Error {
  readonly error: { "@code": string; $text?: string };
  readonly extraText?: string;
  readonly url: string;
  constructor({
    error,
    extraText,
    url,
  }: {
    error: OaiError["error"];
    extraText: OaiError["extraText"];
    url: OaiError["url"];
  }) {
    super(
      `Error response from OAI: [${error["@code"]}]` +
        (error["$text"] ? " " + error["$text"] : "") +
        extraText +
        " Tried to fetch " +
        url,
    );
    this.error = error;
    this.extraText = extraText;
    this.url = url;
  }
}

export type FromOaiOptions<T extends FromOaiOptionsListRecord | FromOaiOptionsGetRecord> =
  T extends FromOaiOptionsListRecord
    ? FromOaiOptionsBase & FromOaiOptionsListRecord & CacheOverride
    : FromOaiOptionsBase & FromOaiOptionsGetRecord;

export interface FromOaiOptionsBase extends OaiOptions {
  /** Only include records since this date. DANGEROUS WHEN USED IN COMBINATION WITH CACHING.*/
  since?: Date;
  // cacheOverride?: "use cache" | "do not cache";
  skipTrim?: boolean;
  skipEnrich?: boolean;
  /**
   * Choose what keys we want to get the records for.
   * Each match will produce a new record.
   * Nested keys should use dot notation:
   *
   * eg: { selectors: "header.subHeader.anotherSubheader" }
   * returns { header: { subHeader: { anotherSubheader: { key: value }}}}
   */
  selectors?: string | string[];
}
type CacheOverride = {
  /** Manually override whether the data should be cached. */
  cacheOverride?: "use cache" | "do not cache";
  /** How old the oldest record in the cache is allowed to be before the cache is fully cleared. */
  maxCacheAgeDays?: number;
};
export interface FromOaiOptionsListRecord {
  set?: ListRecordsOptions["set"];
  metadataPrefix?: ListRecordsOptions["metadataPrefix"];
  identifier?: never;
}

export interface FromOaiOptionsGetRecord {
  metadataPrefix?: GetRecordOptions["metadataPrefix"];
  identifier: GetRecordOptions["identifier"];
  set?: never;
  cacheOverride?: never;
  maxCacheAgeDays?: never;
}

/**
 * Read records from an open archive initiative API.
 *
 * See http://www.openarchives.org/OAI/openarchivesprotocol.html
 */
export default function fromOai<T extends FromOaiOptionsListRecord | FromOaiOptionsGetRecord>(
  opts: FromOaiOptions<T>,
): Middleware {
  return addMwCallSiteToError(
    async function _fromOai(ctx, next) {
      assertOneExtractorPerETL(ctx.app, "fromOai");
      /**
       *  The cache keeps track of the last time it was updated. This value is
       *  called cache.lastUpdated.
       *
       *  Algorithm if caching is used:
       *
       *  - record the time. Call this currentRunStart.
       *  - read records from the API since cache.lastUpdated:
       *      if a record is marked as deleted:
       *        delete it from the cache
       *      else:
       *        save the record to the cache
       *        immediately process it
       *  - record the new cache.lastUpdated
       *  - read records from the cache, but ONLY those which haven't been
       *    modified since currentRunStart: apparently the others have already
       *    been processed while reading records from the API.
       */
      const selectors: string[] = opts?.selectors ? castArray(opts.selectors) : [];
      validatePaths(selectors);

      // loading the first page can take long, so already show a progress of 0%
      ctx.app.showProgress();
      /**
       * We may change the fromOai implementation, causing the cached results to be invalid
       * To force (after a Etl upgrade) to cache to be cleared, increment this number
       */
      const BUST_CACHE_ID = 1;
      const { since, set, metadataPrefix, cacheOverride, maxCacheAgeDays, ...options } = opts;
      if (options.verbosity === undefined) options.verbosity = ctx.app.verbosity;

      const oai = new Oai(options);
      const dirs = [options.url];
      if (metadataPrefix) dirs.push(metadataPrefix);
      if (set) dirs.push(set);
      const cacheDir = ctx.app.getCacheDir("source-oai", ...dirs);
      const cache = (await shouldUseCache(oai, cacheOverride, since)) ? await OaiCache.new(cacheDir) : undefined;
      if (since && cache) {
        // We don't want to throw an error because this is still useful for testing purposes.
        ctx.app.warn(
          "Specifying 'since' in combination with using the cache is not supported and can corrupt the cache!",
        );
      }

      let backgroundPromise: Promise<void> = Promise.resolve();
      let cacheRecordCount = 0;
      let from: ListRecordsOptions["from"];
      if (cache) {
        ctx.app.info("Using disk-based cache: " + cache.directory);
        const lastUpdated = await cache.readDate("lastUpdated");
        const cacheId = await cache.getCacheIndentifier();
        if (!lastUpdated) {
          ctx.app.info("This is a fresh cache!");
          // Clear the cache to make sure any stray records from failed previous
          // runs are removed.
          await cache.setCacheIdentifier(BUST_CACHE_ID);
          backgroundPromise = (await cache.clear()).promise;
          // adding cache override check for testing purposes
        } else if (cacheId !== BUST_CACHE_ID && opts.cacheOverride !== "use cache") {
          ctx.app.info("Clearing the cache due to Etl fromOai code changes");
          backgroundPromise = (await cache.clear()).promise;
          await cache.setCacheIdentifier(BUST_CACHE_ID);
        } else {
          const cacheCreated = await cache.readDate("cacheCreated");
          const cacheAgeMilliseconds = new Date().valueOf() - cacheCreated.valueOf();
          const cacheAgeDays = floor(cacheAgeMilliseconds / MILLISECONDS_IN_A_DAY);
          ctx.app.info(`The cache was created ${cacheAgeDays} days ago.`);
          const lastUpdatedMilliseconds = new Date().valueOf() - lastUpdated.valueOf();
          const lastUpdatedDays = floor(lastUpdatedMilliseconds / MILLISECONDS_IN_A_DAY);
          ctx.app.info(`The cache was last updated ${lastUpdatedDays} days ago.`);
          if (maxCacheAgeDays && cacheAgeDays > maxCacheAgeDays) {
            ctx.app.info(`Clearing the cache because it is older than the allowed ${maxCacheAgeDays} days.`);
            backgroundPromise = (await cache.clear()).promise;
          } else {
            // Make sure that we don't fetch results that are already in the cache
            cacheRecordCount = await cache.countRecords();
            ctx.app.info(`The cache contains ${millify(cacheRecordCount, { precision: 1 })} records.`);
            from = lastUpdated.toISOString().split(".")[0] + "Z";
          }
        }
      }
      // Because the only time we want to support `since` and caching is when
      // testing, and this is probably when testing the cache, we don't want to
      // overwrite the cache-calculated `from`.
      if (since && !from) {
        from = since.toISOString().split(".")[0] + "Z";
      }

      if (opts?.identifier) {
        const { identifier, metadataPrefix } = opts;
        const singleRecord = await oai.GetRecord({ identifier, metadataPrefix });
        if (singleRecord.header.status === "deleted") {
          await cache?.remove(singleRecord);
        } else {
          if (await cache?.add(singleRecord)) ctx.app.incrementProgress(1);
          singleRecord.header.fromCache = false;
          const enriched: Partial<Record> = {};
          if (!opts.skipEnrich) {
            enriched.$recordId = ctx.recordId + 1;
            enriched.$environment = Etl.environment;
          }
          await next(
            { ...enriched, ...(opts.skipTrim ? singleRecord : trimRecordFromSource(singleRecord)) },
            ctx.app.getNewStore(),
          );
        }
        ctx.app.incrementProgress(1);
        return backgroundPromise;
      }

      const recordsIteratorOpts: RecordsIteratorOptions = {
        from,
        set,
        metadataPrefix: await oai.getMetadataPrefix(metadataPrefix),
        firstResponseCallback: async (totalAmmount) => {
          ctx.app.info(`Fetching a total of ${millify(totalAmmount, { precision: 1 })} records from the OAI API.`);
          ctx.app.setTotalProgress(totalAmmount + cacheRecordCount);
        },
      };

      if (options.verbosity! > 2)
        recordsIteratorOpts.responseCallback = async (completeListSize, cursor, elapsed) => {
          ctx.app.info(
            `OAI-PMH update: cursor = ${millify(cursor, { precision: 1 })} for ${millify(completeListSize, {
              precision: 1,
            })} records in ${msTohoursMinutSeconds(elapsed) ?? `${millify(elapsed, { precision: 1 })} ms`}.`,
          );
        };
      const apiRecordsIterator = oai.recordsIterator(recordsIteratorOpts);

      const currentRunStart = new Date();
      let pendingNext = pReflect(apiRecordsIterator.next());
      while (true) {
        const iteratorResult = await pendingNext;
        if (iteratorResult.isRejected) throw iteratorResult.reason;
        if (iteratorResult.value.done) break;
        // Fetch next record, while we're process the results of the current record
        pendingNext = pReflect(apiRecordsIterator.next());
        for (const record of iteratorResult.value.value) {
          if (record.header.status === "deleted") {
            await cache?.remove(record);
          } else {
            // Increment the progress an additional time if the record already
            // existed in the cache, because in that case it has been counted
            // twice: once in the `cache.count()`, and once in the
            // `resumptionInfo["@completeListSize"]`. We will, however, only
            // process it once (now), and skip it when reading from the cache.
            if (await cache?.add(record)) ctx.app.incrementProgress(1);

            // Adding test data for trimming, hard to do without our own OAI-PMH server with data:
            if (process.env.OAI_TESTER) {
              _set(record.header, "OAI_TESTER", JSON.parse(process.env.OAI_TESTER));
            }

            /**
             * Process records using selectors first, as each match on a selector will produce a new record
             * As in one record may result various new records
             */
            if (selectors.length && cacheOverride !== "use cache") {
              const matchedRecords: Record[] = [];
              for (const selector of selectors) {
                const match = matchFromRecord(record, selector);
                if (match) matchedRecords.push(match);
              }
              for (const matchedRecord of matchedRecords) {
                matchedRecord.fromCache = false;
                const enriched: Partial<Record> = {};
                if (!opts.skipEnrich) {
                  enriched.$recordId = ctx.recordId + 1;
                  enriched.$environment = Etl.environment;
                }
                await next(
                  { ...enriched, ...(opts.skipTrim ? matchedRecord : trimRecordFromSource(matchedRecord)) },
                  ctx.app.getNewStore(),
                );
              }
            } else {
              record.header.fromCache = false;
              const enriched: Partial<Record> = {};

              if (!opts.skipEnrich) {
                enriched.$recordId = ctx.recordId + 1;
                enriched.$environment = Etl.environment;
              }
              const returnRecord = opts.verb === "ListIdentifiers" ? record.header : record;
              await next(
                { ...enriched, ...(opts.skipTrim ? returnRecord : trimRecordFromSource(returnRecord)) },
                ctx.app.getNewStore(),
              );
            }
          }
          // going to be hard to update the status correctly as we don't know how many matches to expect.
          ctx.app.incrementProgress(1);
        }
      }

      if (cache) {
        await cache.writeDate("lastUpdated");
        let recordsReturned = 0;
        for await (const record of cache.iterate(currentRunStart)) {
          if (selectors.length) {
            const matchedRecords: Record[] = [];
            for (const selector of selectors) {
              const match = matchFromRecord(record, selector);
              if (match) matchedRecords.push(match);
            }
            for (const matchedRecord of matchedRecords) {
              matchedRecord.fromCache = true;
              recordsReturned++;
              const enriched: Partial<Record> = {};
              if (!opts.skipEnrich) {
                enriched.$recordId = ctx.recordId + 1;
                enriched.$environment = Etl.environment;
              }
              await next(
                { ...enriched, ...(opts.skipTrim ? matchedRecord : trimRecordFromSource(matchedRecord)) },
                ctx.app.getNewStore(),
              );
            }
          } else {
            recordsReturned++;
            record.header.fromCache = true;
            await next(record, ctx.app.getNewStore());
          }
          ctx.app.incrementProgress(1);
        }
        ctx.app.info(`Returned ${recordsReturned} record${recordsReturned === 1 ? "" : "s"} from the cache.`);
      }

      // Repeating this message at the end because someone may have missed it
      // because of lots of shaclValidate output
      if (since && cache) {
        ctx.app.warn(
          "I repeat: specifying 'since' in combination with using the cache is not supported and can corrupt the cache!",
        );
      }
      return backgroundPromise;
    },
    { sourceFuncName: "_fromOai" },
  );
}

async function shouldUseCache(
  oai: Oai,
  userOverride: FromOaiOptions<ListRecordsOptions>["cacheOverride"],
  since: Date | undefined,
) {
  return (
    userOverride === "use cache" || (!since && !userOverride && (await oai.identify()).deletedRecord === "persistent")
  );
}

type Verb = keyof VerbOptions;
interface VerbOptions {
  // http://www.openarchives.org/OAI/openarchivesprotocol.html#Identify
  Identify: {};
  // http://www.openarchives.org/OAI/openarchivesprotocol.html#ListRecords
  ListRecords:
    | ListRecordsOptions
    | {
        resumptionToken: string;
      };
  ListIdentifiers:
    | ListRecordsOptions
    | {
        resumptionToken: string;
      };
  ListSets: { resumptionToken?: string };
  // http://www.openarchives.org/OAI/openarchivesprotocol.html#ListMetadataFormats
  ListMetadataFormats: {
    /** http://www.openarchives.org/OAI/openarchivesprotocol.html#UniqueIdentifier */
    identifier?: string;
  };
  // http://www.openarchives.org/OAI/openarchivesprotocol.html#GetRecord
  GetRecord: GetRecordOptions;
}

type GetRecordOptions = {
  identifier: string;
  metadataPrefix: string;
};

type ListRecordsOptions = {
  metadataPrefix: string;
  set?: string;
  /** must be ISO date(time) format */
  from?: string;
  /** must be ISO date(time) format */
  until?: string;
};

/** http://www.openarchives.org/OAI/openarchivesprotocol.html#Identify */
type IdentifyResponse = {
  repositoryName: string;
  baseURL: string;
  protocolVersion: string;
  earliestDatestamp: string;
  deletedRecord: "no" | "transient" | "persistent";
  granularity: string;
  adminEmail: string | string[];
  compression?: string | string[];
  description?: { [key: string]: any } | { [key: string]: any }[];
};

/** http://www.openarchives.org/OAI/openarchivesprotocol.html#Record */
export type OaiRecordHeader = {
  fromCache: boolean;
  identifier: string;
  datestamp: string;
  setSpec?: string | string[];
  status?: "deleted";
};

export type OaiRecord = {
  header: OaiRecordHeader;
  metadata: any;
  about?: any[];
};

type ResumptionInfo = {
  "@completeListSize": number;
  "@cursor": number;
  /** the resumption token */
  $text?: string;
};

type SetInfo = { setSpec: string; setName: string };

export interface OaiOptions {
  /** URL of the OAI api, excluding the `?` and anything that follows it. */
  url: string;
  verb?: "ListRecords" | "ListIdentifiers";
  verbosity?: number;
  /** Timeout of the request to the OAI-PMH server in **minutes** (not (milli)seconds!) */
  timeout?: number;
}

export class Oai {
  public url: string;
  public verbosity: number;
  public timeout: number;
  public verb?: "ListRecords" | "ListIdentifiers";

  constructor(opts: OaiOptions) {
    const { url, verbosity, timeout, verb } = opts;
    this.url = url;
    this.verb = verb;
    this.verbosity = verbosity ?? 0;
    this.timeout = (timeout ?? 1) * 60 * 1000;
  }

  public async fetch<V extends Verb>(verb: V, options: VerbOptions[V]): Promise<any> {
    const url = this.url + "?" + new URLSearchParams({ verb: verb, ...options });
    if (this.verbosity > 1) console.info("fetching", url);
    const response = await pTimeout(fetch(url), {
      milliseconds: this.timeout,
      message: `Request to ${url} timed out (timeout is set to ${this.timeout} ms)`,
    });

    if (!response.ok)
      throw new Error(
        `[${response.status}: ${response.statusText}] Failed to fetch ${url}: ${await response.text()}` +
          (response.status === 500 ? " You may want to specify the argument `set` in the options to fromOai" : ""),
      );

    const contentTypeHeader = response.headers.get("Content-Type") ?? "text/xml";
    const contentType = contentTypeHeader.split(";")[0].trim().toLowerCase();

    let responseJson: any;
    if (contentType === "application/json") {
      responseJson = await response.json();
    } else {
      const parserOptions: XmlParserOptions = {
        attributeNamePrefix: "@",
        ignoreAttributes: false,
        // Do not post-process attribute values, e.g. trimming them, casting to boolean, or trying to magically cast to number
        // See https://issues.triply.cc/issues/6940
        parseAttributeValue: false,
        parseTagValue: false,
        textNodeName: "$text",
        alwaysCreateTextNode: true,
        isArray: (_1, jPath, _2, isAttribute) =>
          !isAttribute && jPath.startsWith("OAI-PMH.ListRecords.record.metadata.record."),
      };
      const xmlParser = new XMLParser(parserOptions);
      const body = await response.text();
      if (this.verbosity > 2) console.info("response:", body);
      responseJson = await xmlParser.parse(body);
    }

    assertIsObject(
      responseJson,
      `Expected an object as OAI response to ${url}. Response JSON: ` + JSON.stringify(responseJson),
    );
    assertIn("OAI-PMH", responseJson, url);
    responseJson = responseJson["OAI-PMH"];

    if ("error" in responseJson) {
      const error = responseJson.error;
      let extraText = "";
      if (verb === "ListRecords" && error["@code"] === "badArgument" && error["$text"].includes("Set")) {
        extraText = ` Available sets: ${(await this.listSets()).map((s) => s.setSpec).join(", ")}.`;
      }
      throw new OaiError({ error, url, extraText });
    }

    assertIn(verb, responseJson, url);
    return responseJson[verb];
  }

  public async identify(): Promise<IdentifyResponse> {
    return stringifyTextNodes(await this.fetch("Identify", {}));
  }

  public async listMetadataFormats(): Promise<
    Array<{ metadataPrefix: string; schema: string; metadataNamespace: string }>
  > {
    const response = await this.fetch("ListMetadataFormats", {});
    assertIn("metadataFormat", response);
    return castArray(response["metadataFormat"]).map(stringifyTextNodes) as any[];
  }

  public async GetRecord(opts: {
    identifier: VerbOptions["GetRecord"]["identifier"];
    metadataPrefix?: VerbOptions["GetRecord"]["metadataPrefix"];
  }): Promise<OaiRecord> {
    const { identifier, metadataPrefix } = opts;
    const ensureMetadataPrefix = metadataPrefix || "oai_dc";
    const response = await this.fetch("GetRecord", { identifier, metadataPrefix: ensureMetadataPrefix });
    assertIn("record", response);
    response.record.header = stringifyTextNodes(response.record.header);
    return response.record;
  }

  public async listRecordsPage(
    opts: VerbOptions["ListRecords"],
  ): Promise<{ record: OaiRecord[]; resumptionToken?: ResumptionInfo }> {
    if (this.verb === "ListIdentifiers") return this.listIdentifierPage(opts);
    if ("from" in opts && !opts.from) delete opts.from;
    if ("set" in opts && !opts.set) delete opts.set;
    const response = await this.fetch("ListRecords", opts);
    assertIn("record", response);
    response.record = castArray(response.record).map((record: OaiRecord) => {
      if (!record)
        throw new Error(
          "One of the records is not defined. This means the OAI api doesn't follow the spec. Please report this to owner of the OAI-PMH Api.",
        );
      record.header = stringifyTextNodes(record.header);
      return record;
    });
    if ("resumptionToken" in response) response.resumptionToken = parseResumptionInfo(response.resumptionToken);
    return response;
  }

  public async listIdentifierPage(
    opts: VerbOptions["ListRecords"],
  ): Promise<{ record: OaiRecord[]; resumptionToken?: ResumptionInfo }> {
    if ("from" in opts && !opts.from) delete opts.from;
    if ("set" in opts && !opts.set) delete opts.set;
    const response = await this.fetch("ListIdentifiers", opts);
    assertIn("header", response);
    response.record = castArray(response.header).map((record: OaiRecordHeader) => {
      if (!record)
        throw new Error(
          "One of the records is not defined. This means the OAI api doesn't follow the spec. Please report this to owner of the OAI-PMH Api.",
        );
      return { header: stringifyTextNodes(record) };
    });
    if ("resumptionToken" in response) response.resumptionToken = parseResumptionInfo(response.resumptionToken);
    return response;
  }

  public async listSetsPage(
    opts: VerbOptions["ListSets"],
  ): Promise<{ set: SetInfo[]; resumptionToken?: ResumptionInfo }> {
    const response = await this.fetch("ListSets", opts);
    assertIn("set", response);
    response.set = castArray(response.set).map(stringifyTextNodes);
    if ("resumptionToken" in response) response.resumptionToken = parseResumptionInfo(response.resumptionToken);
    return response;
  }

  public async getMetadataPrefix(metadataPrefix: string | undefined) {
    const supportedPrefixes = (await this.listMetadataFormats()).map((f) => f.metadataPrefix);
    if (supportedPrefixes.length === 0) throw new Error("OAI lists no metadata formats.");
    if (metadataPrefix) {
      if (!supportedPrefixes.includes(metadataPrefix))
        throw new Error(
          `'${metadataPrefix}' is not listed as a supported metadataPrefix. Choose from: ${supportedPrefixes}`,
        );
    } else {
      if (supportedPrefixes.length !== 1)
        throw new Error("Please specify a metadataPrefix. Choose from: " + supportedPrefixes);
      metadataPrefix = supportedPrefixes[0];
    }
    return metadataPrefix;
  }

  public async listSets() {
    const sets: SetInfo[] = [];
    for await (const set of this.setsIterator()) {
      sets.push(set);
    }
    return sets;
  }

  public setsIterator() {
    return new OaiSetsIterator(this);
  }

  public recordsIterator(opts: RecordsIteratorOptions) {
    return new OaiRecordsIterator(this, opts);
  }
}

interface RecordsIteratorOptions extends ListRecordsOptions {
  firstResponseCallback?: OaiRecordsIterator["firstResponseCallback"];
  responseCallback?: OaiRecordsIterator["responseCallback"];
}

class OaiRecordsIterator implements AsyncIterator<OaiRecord[]>, AsyncIterable<OaiRecord[]> {
  readonly oai: Oai;
  started: boolean;
  resumptionToken: string | undefined;
  readonly firstResponseCallback: (amount: number) => Promise<void> = async () => {};
  readonly responseCallback: (completeListSize: number, cursor: number, elapsed: number) => Promise<void> =
    async () => {};
  readonly listRecordsOptions: ListRecordsOptions;

  constructor(oai: Oai, opts: RecordsIteratorOptions) {
    this.oai = oai;
    const { firstResponseCallback, responseCallback, ...listRecordsOptions } = opts;
    this.firstResponseCallback = firstResponseCallback ?? (async () => {});
    this.responseCallback = responseCallback ?? (async () => {});
    this.started = false;
    this.listRecordsOptions = listRecordsOptions;
  }

  public async next() {
    let options: VerbOptions["ListRecords"];
    if (!this.started) {
      this.started = true;
      options = this.listRecordsOptions;
    } else if (this.resumptionToken) {
      options = { resumptionToken: this.resumptionToken };
    } else {
      return { done: true, value: undefined } as const;
    }
    let result;
    try {
      const time = new Date().getTime();
      result = await this.oai.listRecordsPage(options);
      if ("resumptionToken" in options) {
        const completeListSize = result.resumptionToken?.["@completeListSize"] ?? -1;
        const cursor = result.resumptionToken?.["@cursor"] ?? -1;
        await this.responseCallback(completeListSize, cursor, new Date().getTime() - time);
      }
    } catch (e) {
      if (e instanceof OaiError && e.error["@code"] === "noRecordsMatch" && !("resumptionToken" in options)) {
        // This is the first call to the API, and apparently there's just an
        // empty list.
        await this.firstResponseCallback(0);
        return { done: true, value: undefined } as const;
      }
      throw e;
    }
    this.resumptionToken = result.resumptionToken?.["$text"];
    if (!("resumptionToken" in options)) {
      await this.firstResponseCallback(result.resumptionToken?.["@completeListSize"] ?? result.record.length);
    }

    return {
      value: result.record,
      done: false,
    };
  }

  public [Symbol.asyncIterator]() {
    return this;
  }
}

class OaiSetsIterator implements AsyncIterator<SetInfo>, AsyncIterable<SetInfo> {
  oai: Oai;
  started: boolean;
  resumptionToken: string | undefined;
  /** last element of the array is next up */
  buffer: SetInfo[] = [];

  constructor(oai: Oai) {
    this.oai = oai;
    this.started = false;
  }

  public async next() {
    if (this.buffer.length === 0) {
      let options: VerbOptions["ListSets"];
      if (!this.started) {
        this.started = true;
        options = {};
      } else if (this.resumptionToken) {
        options = { resumptionToken: this.resumptionToken };
      } else {
        return { done: true, value: undefined } as const;
      }
      const result = await this.oai.listSetsPage(options);
      this.buffer = result.set.reverse(); // pop from the back
      this.resumptionToken = result.resumptionToken?.["$text"];
    }
    return {
      value: this.buffer.pop()!,
      done: false,
    };
  }

  public [Symbol.asyncIterator]() {
    return this;
  }
}

export class OaiCache {
  readonly directory: string;
  readonly prefixSize: number = 2;

  private constructor(directory: OaiCache["directory"]) {
    this.directory = directory;
  }

  public static async new(cacheDir: string) {
    const cache = new OaiCache(cacheDir);
    await fs.ensureDir(cacheDir);
    await cache.writeDate("cacheCreated");
    return cache;
  }
  private getCacheIdPath() {
    return resolve(this.directory, ".cacheId");
  }
  public async getCacheIndentifier(): Promise<number> {
    const cacheIdPath = await this.getCacheIdPath();
    if (!(await fs.pathExists(cacheIdPath))) return 0;
    return +(await fs.readFile(cacheIdPath, "utf-8"));
  }
  public async setCacheIdentifier(cacheId: number) {
    const cacheIdPath = this.getCacheIdPath();
    return fs.writeFile(cacheIdPath, "" + cacheId);
  }
  public async readDate(name: "lastUpdated"): Promise<Date | undefined>;
  public async readDate(name: "cacheCreated"): Promise<Date>;
  public async readDate(name: "lastUpdated" | "cacheCreated") {
    const filename = resolve(this.directory, name + ".isodate.txt");
    let date: Date | undefined;
    if (await fs.pathExists(filename)) date = new Date(await fs.readFile(filename, "utf-8"));
    if (name === "cacheCreated" && !date)
      throw new Error(
        "cacheCreated wasn't defined. Please report this to a developer if you haven't been messing with the cache yourself.",
      );
    return date;
  }

  /** Write a date (with day-precision) to the cache metadata. */
  public async writeDate(name: "lastUpdated" | "cacheCreated") {
    const path = resolve(this.directory, name + ".isodate.txt");
    if (name === "cacheCreated" && (await fs.pathExists(path))) return;
    // We don't have to save yesterdays date for `lastUpdated`, because we
    // send the API a minute-precise ISO datetime which specifies the _start_
    // of the lastUpdated day.
    const dateString = new Date().toISOString().split("T")[0];
    return fs.writeFile(path, dateString, "utf-8");
  }

  /**
   *  Clear the cache.
   *  The inner promise can safely be executed while writing new entries.
   */
  public async clear() {
    const removePath = this.directory + "-to-be-removed-" + Math.random();
    await fs.move(this.directory, removePath);
    await fs.mkdir(this.directory);
    await this.writeDate("cacheCreated");
    return {
      promise: fs.remove(removePath),
    };
  }

  /** Get a filesystem-safe unique ID for a record */
  static id(record: OaiRecord) {
    return md5OfArray([record.header.identifier]);
  }

  filesystemInfo(record: OaiRecord) {
    const id = OaiCache.id(record);
    const dir = resolve(this.directory, id.slice(0, this.prefixSize));
    const fullPath = resolve(dir, id.slice(this.prefixSize) + ".json");
    return { dir, fullPath };
  }

  /**
   *  Iterate over all the cached records, in arbitrary order.
   *
   *  @param cutOffTimeForFilesToInclude
   *           If the last modified date of the file on disc is after
   *           `cutOffTimeForFilesToInclude` the record will be excluded.
   */
  public async *iterate(cutOffTimeForFilesToInclude?: Date) {
    for (const directory of await fs.readdir(this.directory)) {
      const dirpath = resolve(this.directory, directory);
      if (!(await fs.stat(dirpath)).isDirectory()) continue;
      for (const filename of await fs.readdir(dirpath)) {
        const path = resolve(this.directory, directory, filename);
        // Was breaking trying to read set cache directories
        if ((await fs.stat(path)).isDirectory()) continue;
        if (cutOffTimeForFilesToInclude && (await fs.stat(path)).mtime > cutOffTimeForFilesToInclude) continue;
        // Avoids reading files that aren't json
        if (!path.endsWith("json")) continue;
        yield (await fs.readJson(path)) as OaiRecord;
      }
    }
  }

  /**
   *  Write a record to cache. Overwrites existing entry with the same ID.
   *
   *  @returns Whether the entry already existed in the cache.
   */
  public async add(record: OaiRecord) {
    const { dir, fullPath } = this.filesystemInfo(record);
    await fs.ensureDir(dir);
    const alreadyThere = await fs.pathExists(fullPath);
    await fs.writeJson(fullPath, record);
    return alreadyThere;
  }

  /**
   *  Remove a record from the cache.
   */
  public async remove(record: OaiRecord) {
    const { fullPath } = this.filesystemInfo(record);
    return fs.remove(fullPath);
  }

  /**
   *  Count the number of entries in the cache.
   */
  public async countRecords() {
    return sum(
      await Promise.all(
        (await fs.readdir(this.directory)).map(async (subdir) => {
          const path = resolve(this.directory, subdir);
          if ((await fs.stat(path)).isDirectory()) return (await fs.readdir(path)).length;
          else return 0;
        }),
      ),
    );
  }
}

function parseResumptionInfo(info: any): ResumptionInfo {
  assertIn("@completeListSize", info);
  assertIn("@cursor", info);
  return {
    "@completeListSize": new Number(info["@completeListSize"]).valueOf(),
    "@cursor": new Number(info["@cursor"]).valueOf(),
    $text: info["$text"],
  };
}

function assertIn<K extends string, J extends { [key: string]: unknown }>(key: K, json: J, url?: string) {
  if (!(key in json)) {
    throw new Error(
      `Expected '${key}' to be in the OAI response${
        url ? " of " + url : ""
      }. This is most likely because the OAI-PMH server is unresponsive. You should contact the owner of the service. Response JSON: ` +
        JSON.stringify(json),
    );
  }
}

/**
 *  Recursively convert any node that looks like `{ '$text': string }` to a simple `string`
 */
function stringifyTextNodes(object: { [key: string]: any }): any {
  if (typeof object === "object") {
    const keys = Object.keys(object);
    if (keys.length === 1 && keys[0] === "$text") {
      return object["$text"];
    } else {
      return mapValues(object, (sub) => stringifyTextNodes(sub));
    }
  }
  return object;
}
